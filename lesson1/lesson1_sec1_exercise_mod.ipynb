{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson1_sec1_exercise_mod.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYOnZhT30bGu",
        "colab_type": "text"
      },
      "source": [
        "# Lesson1 手書き文字認識をしよう（ニューラルネットワーク入門）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ju7RayK0bGy",
        "colab_type": "text"
      },
      "source": [
        "## 目次\n",
        "\n",
        "- Section1 解説\n",
        "  - 1.1 Keras実装プロセス\n",
        "  - 1.2 各モデルLayer\n",
        "  - 1.3 損失関数\n",
        "  - 1.4 評価関数\n",
        "  - 1.5 Functional API\n",
        "  - 1.6 確認問題\n",
        "- Section2 実装①\n",
        "  - 2.1 MNISTによるMLPの復習\n",
        "- Section3 テクニック・発展内容\n",
        "  - 3.1 前処理\n",
        "  - 3.2 勾配に関するテクニック\n",
        "    - 3.2.1 最適化アルゴリズム (optimizer)\n",
        "    - 3.2.2 活性化関数 (activation)\n",
        "    - 3.2.3 初期化 (initializer)\n",
        "  - 3.3 過学習に関するテクニック\n",
        "    - 3.3.1 正則化 (regularization)\n",
        "    - 3.3.2 早期終了 (early stopping)\n",
        "    - 3.3.3 ドロップアウト (dropout)\n",
        "  - 3.4 確認問題\n",
        "- Section4 実装②\n",
        "  - 4.1 Fashion MNIST\n",
        "  - 4.2 実装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pNejt1B0bG1",
        "colab_type": "text"
      },
      "source": [
        "## Section1 解説"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2n0HLjd0bG3",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Keras実装プロセス"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVNVVU2o0bG5",
        "colab_type": "text"
      },
      "source": [
        "今回は早速Kerasでの実装方法を見ていきたいと思います。\n",
        "\n",
        "まず、Kerasの雰囲気を感じ取ってもらうため、Kerasで機械学習を行う際に、\n",
        "\n",
        "1. いったいどういった手順を踏むか\n",
        "2. コードはどう書くのか\n",
        "\n",
        "をざっくりと見ていきたいと思います。\n",
        "\n",
        "実装は、MLP(Multi Layer Perceptron)とCNN(Convolutional Neural Network)の2つで行い、その実装およびモデル構造、学習結果の比較をしてみます。\n",
        "\n",
        "\n",
        "題材としては、手書き数字画像を入力データ、対応する数字の値を出力データとする教師あり学習（分類）です。\n",
        "\n",
        "参考：https://keras.io/ja/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFKVp80t0bG8",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.0 データの用意\n",
        "まず機械学習を適用するデータを用意しなければ始まりません。\n",
        "\n",
        "ここでは、機械学習で頻繁に用いられる、MNISTの手書き数字データセットを用います。\n",
        "\n",
        "データセットの中身は、\n",
        "\n",
        "* x:手書き数字画像(28×28)\n",
        "* y:正解のラベル（xの画像が表す数字）\n",
        "\n",
        "となっていますが、\n",
        "\n",
        "* (x_train, y_train):モデルの学習用\n",
        "* (x_test, y_test):モデルの評価用\n",
        "\n",
        "と区別してあります。\n",
        "\n",
        "機械学習では汎化性能の向上が至上命題なので、学習用のデータだけでなく評価用のデータが必要になります。\n",
        "\n",
        "MNISTのデータセットも、全てのデータを使用するのではなく、学習用と評価用に予め分割してあるわけです。\n",
        "\n",
        "（分割は事前に行っておく必要があります。評価用のデータまで使用して学習を行うのは、カンニングと変わらなくなってしまいます。）\n",
        "\n",
        "なお、KerasではこのMNISTのデータセットに限らず、機械学習で頻繁に用いられるデータセットがいくつも用意されており、性能評価を手軽に行えます。\n",
        "\n",
        "keras.datasets以下からimportすることで使用できますので、ぜひ使っていきましょう。\n",
        "\n",
        "Kerasから直接使用できるデータセットの一覧はこちら( https://keras.io/ja/datasets/ )です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIjKuxuD0bG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "899df608-d39c-4488-ac85-c05157bcbfe3"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# MNISTデータセットをダウンロードし、変数にセット\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3pSTYqA0bHI",
        "colab_type": "text"
      },
      "source": [
        "今回扱うMNISTの手書き数字のデータを下記で表示してみましょう。\n",
        "\n",
        "表示する際には、matplotlibを用います。これはPythonでグラフの表示をする際に標準的に用いられるライブラリです。\n",
        "\n",
        "中でもpyplotは最もよく使用されるモジュールで、標準的な描画処理の多くに対応しています。\n",
        "\n",
        "ここでは詳しくは説明しませんが、公式のマニュアルでpyplotに含まれる関数に目を通しておくことをお勧めします。\n",
        "\n",
        "参考：https://matplotlib.org/api/pyplot_api.html\n",
        "\n",
        "なお、jupyer notebook上でmatplotlibの結果を表示するには、`%matplotlib inline`を冒頭で宣言する必要があります。\n",
        "\n",
        "（ちなみに、このような`%`あるいは`%%`から始まるjupyter notebookに対するコマンドはマジックコマンドと呼ばれ、他にも様々なものが存在します。）\n",
        "\n",
        "また、MNISTの画像には、それぞれに対して画像が示す数字が正解のラベルとして与えられています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-XaTkOc0bHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "c2fec4fe-3e47-4a9f-939c-6464195513cf"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(9, 15))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05, wspace=0.05)\n",
        "\n",
        "# 各MNIST画像の上に（タイトルとして）対応するラベルを表示\n",
        "for i in range(30):\n",
        "    ax = fig.add_subplot(3, 10, i + 1, xticks=[], yticks=[])\n",
        "    ax.set_title(str(y_train[i]))\n",
        "    ax.imshow(x_train[i], cmap='gray')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp0AAAHNCAYAAABcs8BUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 648x1080 with 30 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZCxZxgl0bHX",
        "colab_type": "text"
      },
      "source": [
        "これから、このMNISTの各画像が0～9のどの数字であるか分類する事を考えていきます。\n",
        "\n",
        "問題としては、いわゆる10クラス分類の問題です。（分類先のことを**クラス**と呼びます）\n",
        "\n",
        "さて、ここで特に分類タスクの際に気をつけたいことがあります。\n",
        "\n",
        "分類タスクの時の出力データはラベルですが、ラベルは数字としての大小には意味がないということです。\n",
        "\n",
        "というのも、グループの名前として数字を割り振っているだけであるためです。こうした数字を**名義尺度**と呼びます。\n",
        "\n",
        "機械学習のアルゴリズムでは数字の大小に意味があるものとして扱ってしまうため、名義尺度をうまく変換しなければなりません。\n",
        "\n",
        "この名義尺度を変換する表現として使用されるのが、**one-hot表現**と呼ばれるものです。\n",
        "\n",
        "全体で3クラスあるときの各クラスの表現は次の通りです。\n",
        "\n",
        "<ul>\n",
        "    <li>1：$[1,0,0]$</li>\n",
        "    <li>2：$[0,1,0]$</li>\n",
        "    <li>3：$[0,0,1]$</li>\n",
        "</ul>\n",
        "\n",
        "長さ3のベクトルを用いて、各クラスの対応する要素のみ1として表現するということです。\n",
        "\n",
        "一般化すると、全体で$K$クラスある時、$k$番目のクラスに属するとき、\n",
        "\n",
        "$\\underset{K}{\\underbrace{[0,\\cdots,0,\\overset{k}{\\check{1}},0,\\cdots,0]}}$\n",
        "\n",
        "と表現するということです。\n",
        "\n",
        "このone-hot表現への変換を行ってくれる関数がKerasにはあります。\n",
        "\n",
        "keras.utils.to_categorical関数がその関数です。さっそくMNISTのデータセットにも適用してみましょう。\n",
        "\n",
        "https://keras.io/ja/utils/#to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDQdKIyfvZCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BASIC or CNN\n",
        "model_structure=\"CNN\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBvnPZCU0bHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "if model_structure==\"CNN\":\n",
        "    # for CNN \n",
        "    x_train = x_train.reshape(-1, 28, 28).astype(np.float32)\n",
        "    x_test = x_test.reshape(-1, 28, 28).astype(np.float32)\n",
        "else:\n",
        "    # 入力画像を行列(28x28)からベクトル(長さ784)に変換\n",
        "    x_train = x_train.reshape(-1, 784)\n",
        "    x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "# 名義尺度の値をone-hot表現へ変換\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUUkN6qj0bHi",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.1 モデル構築\n",
        "\n",
        "学習に使用するMLPのモデルを構築します。具体的には、どんなlayer（層）をどこに配置するか、また各layerのユニット数はいくつかを指定していきます。\n",
        "\n",
        "このモデルを構築するための「容器」として機能するのが、keras.models.Sequentialクラスです。\n",
        "\n",
        "この「容器」の中に、Sequential.add関数によってkeras.layersに定義されているlayerクラス（後で詳述）を積み重ねていくことでモデルの構築を行います。\n",
        "\n",
        "layerをSequentialクラスに積み終えたら、最後にSequential.compile関数でモデルの学習処理について指定し、モデル構築は完了です。\n",
        "\n",
        "compile関数では\n",
        "\n",
        "* optimizer（最適化手法）\n",
        "* loss（損失関数）\n",
        "* metrics（評価関数（任意））\n",
        "\n",
        "を指定することになります。（いずれも後で詳述）\n",
        "\n",
        "https://keras.io/ja/models/sequential/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rIGYTTK0bHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデル構築用ライブラリをインポート\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "\n",
        "# CNNモデル用ライブラリ\n",
        "from tensorflow.python.keras.layers import Conv2D, Convolution2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.python.keras import initializers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ25Y8nL0bHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNNモデルの場合\n",
        "if model_structure==\"CNN\":\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "    input_shape = (28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8TOq83u0bHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 「容器」へ各layer（Dense, Activation）を積み重ねていく（追加した順に配置されるので注意）\n",
        "# 最初のlayerはinput_shapeを指定して、入力するデータの次元を与える必要がある\n",
        "def basic_model():\n",
        "    model.add(Dense(units=256, input_shape=(784,)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(units=100))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(units=10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# CNNモデル\n",
        "def cnn_model():\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(units=10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "# CNNモデル w/Dropout\n",
        "def cnn_w_dropout():\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=10))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "# CNNモデル w/Batch Normalization\n",
        "def cnn_w_batchnorm():\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(units=10))\n",
        "    model.add(Activation('softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq7BxPyz0bH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "61621608-156a-48e0-b9db-2d378556a898"
      },
      "source": [
        "# モデルの「容器」を作成\n",
        "model = Sequential()\n",
        "\n",
        "# model構築\n",
        "if model_structure==\"CNN\":\n",
        "    cnn_model()\n",
        "#    cnn_w_dropout()\n",
        "#    cnn_w_batchnorm()\n",
        "else:\n",
        "    basic_model()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSEVpmwMo1U8",
        "colab_type": "text"
      },
      "source": [
        "視覚的にわかるよう、モデル構造を図示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBmICHhQOX57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "552fcb82-4673-48e3-8a00-ba11efa8fdc9"
      },
      "source": [
        "!git clone https://github.com/scpepper69/convnet-drawer.git convert_drawer\n",
        "import sys\n",
        "sys.path.append('./convert_drawer/')\n",
        "from keras_util import convert_drawer_model\n",
        "from keras_models import AlexNet\n",
        "from matplotlib_util import save_model_to_file\n",
        "from IPython.display import *\n",
        "\n",
        "# get Keras sequential model\n",
        "#keras_sequential_model = AlexNet.get_model()\n",
        "draw_model = convert_drawer_model(model)\n",
        "\n",
        "# save as svg file\n",
        "draw_model.save_fig('model_structure.svg')\n",
        "display_svg(SVG('model_structure.svg'))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'convert_drawer'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 283 (delta 38), reused 46 (delta 20), pack-reused 219\u001b[K\n",
            "Receiving objects: 100% (283/283), 959.06 KiB | 8.80 MiB/s, done.\n",
            "Resolving deltas: 100% (168/168), done.\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<svg height=\"321.1803404061793\" viewBox=\"-40 -153.59017020308966 479.81106550258596 321.1803404061793\" width=\"479.81106550258596\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"0\" x2=\"0\" y1=\"9.100000000000001\" y2=\"-18.9\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"1.0\" x2=\"1.0\" y1=\"9.100000000000001\" y2=\"-18.9\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"16.974097914174997\" x2=\"16.974097914174997\" y1=\"18.9\" y2=\"-9.100000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"17.974097914174997\" x2=\"17.974097914174997\" y1=\"18.9\" y2=\"-9.100000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"0\" x2=\"16.974097914174997\" y1=\"9.100000000000001\" y2=\"18.9\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"0\" x2=\"16.974097914174997\" y1=\"-18.9\" y2=\"-9.100000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"1.0\" x2=\"17.974097914174997\" y1=\"9.100000000000001\" y2=\"18.9\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"1.0\" x2=\"17.974097914174997\" y1=\"-18.9\" y2=\"-9.100000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"0\" x2=\"1.0\" y1=\"9.100000000000001\" y2=\"9.100000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"16.974097914174997\" x2=\"17.974097914174997\" y1=\"18.9\" y2=\"18.9\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"0\" x2=\"1.0\" y1=\"-18.9\" y2=\"-18.9\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"16.974097914174997\" x2=\"17.974097914174997\" y1=\"-9.100000000000001\" y2=\"-9.100000000000001\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"8.987048957087499\" y=\"-28.9\">28x28x1</text>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"67.97409791417499\" x2=\"67.97409791417499\" y1=\"8.450000000000001\" y2=\"-17.549999999999997\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"75.97409791417499\" x2=\"75.97409791417499\" y1=\"8.450000000000001\" y2=\"-17.549999999999997\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"83.73576026305177\" x2=\"83.73576026305177\" y1=\"17.549999999999997\" y2=\"-8.450000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"91.73576026305177\" x2=\"91.73576026305177\" y1=\"17.549999999999997\" y2=\"-8.450000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"67.97409791417499\" x2=\"83.73576026305177\" y1=\"8.450000000000001\" y2=\"17.549999999999997\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"67.97409791417499\" x2=\"83.73576026305177\" y1=\"-17.549999999999997\" y2=\"-8.450000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"75.97409791417499\" x2=\"91.73576026305177\" y1=\"8.450000000000001\" y2=\"17.549999999999997\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"75.97409791417499\" x2=\"91.73576026305177\" y1=\"-17.549999999999997\" y2=\"-8.450000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"67.97409791417499\" x2=\"75.97409791417499\" y1=\"8.450000000000001\" y2=\"8.450000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"83.73576026305177\" x2=\"91.73576026305177\" y1=\"17.549999999999997\" y2=\"17.549999999999997\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"67.97409791417499\" x2=\"75.97409791417499\" y1=\"-17.549999999999997\" y2=\"-17.549999999999997\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"83.73576026305177\" x2=\"91.73576026305177\" y1=\"-8.450000000000001\" y2=\"-8.450000000000001\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"79.85492908861337\" y=\"-27.549999999999997\">26x26x32</text>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"141.73576026305176\" x2=\"141.73576026305176\" y1=\"7.800000000000002\" y2=\"-16.2\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"153.86149279513495\" x2=\"153.86149279513495\" y1=\"7.800000000000002\" y2=\"-16.2\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"156.28498704663033\" x2=\"156.28498704663033\" y1=\"16.2\" y2=\"-7.800000000000002\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"168.4107195787135\" x2=\"168.4107195787135\" y1=\"16.2\" y2=\"-7.800000000000002\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"141.73576026305176\" x2=\"156.28498704663033\" y1=\"7.800000000000002\" y2=\"16.2\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"141.73576026305176\" x2=\"156.28498704663033\" y1=\"-16.2\" y2=\"-7.800000000000002\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"153.86149279513495\" x2=\"168.4107195787135\" y1=\"7.800000000000002\" y2=\"16.2\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"153.86149279513495\" x2=\"168.4107195787135\" y1=\"-16.2\" y2=\"-7.800000000000002\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"141.73576026305176\" x2=\"153.86149279513495\" y1=\"7.800000000000002\" y2=\"7.800000000000002\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"156.28498704663033\" x2=\"168.4107195787135\" y1=\"16.2\" y2=\"16.2\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"141.73576026305176\" x2=\"153.86149279513495\" y1=\"-16.2\" y2=\"-16.2\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"156.28498704663033\" x2=\"168.4107195787135\" y1=\"-7.800000000000002\" y2=\"-7.800000000000002\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"155.07323992088266\" y=\"-26.2\">24x24x64</text>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"218.41071957871353\" x2=\"218.41071957871353\" y1=\"3.900000000000001\" y2=\"-8.1\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"230.53645211079672\" x2=\"230.53645211079672\" y1=\"3.900000000000001\" y2=\"-8.1\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"225.6853329705028\" x2=\"225.6853329705028\" y1=\"8.1\" y2=\"-3.900000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"237.811065502586\" x2=\"237.811065502586\" y1=\"8.1\" y2=\"-3.900000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"218.41071957871353\" x2=\"225.6853329705028\" y1=\"3.900000000000001\" y2=\"8.1\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"218.41071957871353\" x2=\"225.6853329705028\" y1=\"-8.1\" y2=\"-3.900000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"230.53645211079672\" x2=\"237.811065502586\" y1=\"3.900000000000001\" y2=\"8.1\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"230.53645211079672\" x2=\"237.811065502586\" y1=\"-8.1\" y2=\"-3.900000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"218.41071957871353\" x2=\"230.53645211079672\" y1=\"3.900000000000001\" y2=\"3.900000000000001\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"225.6853329705028\" x2=\"237.811065502586\" y1=\"8.1\" y2=\"8.1\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"218.41071957871353\" x2=\"230.53645211079672\" y1=\"-8.1\" y2=\"-8.1\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"225.6853329705028\" x2=\"237.811065502586\" y1=\"-3.900000000000001\" y2=\"-3.900000000000001\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"228.11089254064976\" y=\"-18.1\">12x12x64</text>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"287.81106550258596\" x2=\"287.81106550258596\" y1=\"-119.59017020308964\" y2=\"119.59017020308964\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"287.81106550258596\" x2=\"291.81106550258596\" y1=\"119.59017020308964\" y2=\"119.59017020308964\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"291.81106550258596\" x2=\"291.81106550258596\" y1=\"119.59017020308964\" y2=\"-119.59017020308964\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"291.81106550258596\" x2=\"287.81106550258596\" y1=\"-119.59017020308964\" y2=\"-119.59017020308964\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"289.81106550258596\" y=\"-129.59017020308966\">9216</text>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"341.81106550258596\" x2=\"341.81106550258596\" y1=\"-13.928809012737984\" y2=\"13.928809012737984\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"341.81106550258596\" x2=\"345.81106550258596\" y1=\"13.928809012737984\" y2=\"13.928809012737984\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"345.81106550258596\" x2=\"345.81106550258596\" y1=\"13.928809012737984\" y2=\"-13.928809012737984\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"345.81106550258596\" x2=\"341.81106550258596\" y1=\"-13.928809012737984\" y2=\"-13.928809012737984\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"343.81106550258596\" y=\"-23.928809012737986\">256</text>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"395.81106550258596\" x2=\"395.81106550258596\" y1=\"-1.9905358527674861\" y2=\"1.9905358527674861\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"395.81106550258596\" x2=\"399.81106550258596\" y1=\"1.9905358527674861\" y2=\"1.9905358527674861\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"399.81106550258596\" x2=\"399.81106550258596\" y1=\"1.9905358527674861\" y2=\"-1.9905358527674861\"/>\n<line stroke=\"rgb(0, 0, 0)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"399.81106550258596\" x2=\"395.81106550258596\" y1=\"-1.9905358527674861\" y2=\"-1.9905358527674861\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"397.81106550258596\" y=\"-11.990535852767486\">10</text>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"8.487048957087499\" x2=\"8.487048957087499\" y1=\"0.9750000000000002\" y2=\"-2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"9.487048957087499\" x2=\"9.487048957087499\" y1=\"0.9750000000000002\" y2=\"-2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"10.30570230503482\" x2=\"10.30570230503482\" y1=\"2.025\" y2=\"-0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"11.30570230503482\" x2=\"11.30570230503482\" y1=\"2.025\" y2=\"-0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"8.487048957087499\" x2=\"10.30570230503482\" y1=\"0.9750000000000002\" y2=\"2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"8.487048957087499\" x2=\"10.30570230503482\" y1=\"-2.025\" y2=\"-0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"9.487048957087499\" x2=\"11.30570230503482\" y1=\"0.9750000000000002\" y2=\"2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"9.487048957087499\" x2=\"11.30570230503482\" y1=\"-2.025\" y2=\"-0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"8.487048957087499\" x2=\"9.487048957087499\" y1=\"0.9750000000000002\" y2=\"0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"10.30570230503482\" x2=\"11.30570230503482\" y1=\"2.025\" y2=\"2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"8.487048957087499\" x2=\"9.487048957087499\" y1=\"-2.025\" y2=\"-2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"10.30570230503482\" x2=\"11.30570230503482\" y1=\"-0.9750000000000002\" y2=\"-0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"9.487048957087499\" x2=\"71.91451350139418\" y1=\"-2.025\" y2=\"-8.774999999999999\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"11.30570230503482\" x2=\"71.91451350139418\" y1=\"2.025\" y2=\"-8.774999999999999\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"42.97409791417499\" y=\"42.9\">conv3x3, 32</text>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"42.97409791417499\" y=\"56.9\">stride (1, 1)</text>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"75.85492908861339\" x2=\"75.85492908861339\" y1=\"0.9750000000000002\" y2=\"-2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"83.85492908861339\" x2=\"83.85492908861339\" y1=\"0.9750000000000002\" y2=\"-2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"77.67358243656071\" x2=\"77.67358243656071\" y1=\"2.025\" y2=\"-0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"85.67358243656071\" x2=\"85.67358243656071\" y1=\"2.025\" y2=\"-0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"75.85492908861339\" x2=\"77.67358243656071\" y1=\"0.9750000000000002\" y2=\"2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"75.85492908861339\" x2=\"77.67358243656071\" y1=\"-2.025\" y2=\"-0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"83.85492908861339\" x2=\"85.67358243656071\" y1=\"0.9750000000000002\" y2=\"2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"83.85492908861339\" x2=\"85.67358243656071\" y1=\"-2.025\" y2=\"-0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"75.85492908861339\" x2=\"83.85492908861339\" y1=\"0.9750000000000002\" y2=\"0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"77.67358243656071\" x2=\"85.67358243656071\" y1=\"2.025\" y2=\"2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"75.85492908861339\" x2=\"83.85492908861339\" y1=\"-2.025\" y2=\"-2.025\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"77.67358243656071\" x2=\"85.67358243656071\" y1=\"-0.9750000000000002\" y2=\"-0.9750000000000002\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"83.85492908861339\" x2=\"145.3730669589464\" y1=\"-2.025\" y2=\"-8.1\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"85.67358243656071\" x2=\"145.3730669589464\" y1=\"2.025\" y2=\"-8.1\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"116.73576026305176\" y=\"41.55\">conv3x3, 64</text>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"116.73576026305176\" y=\"55.55\">stride (1, 1)</text>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"149.01037365484103\" x2=\"149.01037365484103\" y1=\"0.6500000000000001\" y2=\"-1.3499999999999999\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"161.13610618692422\" x2=\"161.13610618692422\" y1=\"0.6500000000000001\" y2=\"-1.3499999999999999\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"150.22280922013925\" x2=\"150.22280922013925\" y1=\"1.35\" y2=\"-0.6500000000000001\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"162.34854175222245\" x2=\"162.34854175222245\" y1=\"1.35\" y2=\"-0.6500000000000001\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"149.01037365484103\" x2=\"150.22280922013925\" y1=\"0.6500000000000001\" y2=\"1.35\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"149.01037365484103\" x2=\"150.22280922013925\" y1=\"-1.3499999999999999\" y2=\"-0.6500000000000001\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"161.13610618692422\" x2=\"162.34854175222245\" y1=\"0.6500000000000001\" y2=\"1.35\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"161.13610618692422\" x2=\"162.34854175222245\" y1=\"-1.3499999999999999\" y2=\"-0.6500000000000001\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"1\" stroke-width=\"1\" x1=\"149.01037365484103\" x2=\"161.13610618692422\" y1=\"0.6500000000000001\" y2=\"0.6500000000000001\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"150.22280922013925\" x2=\"162.34854175222245\" y1=\"1.35\" y2=\"1.35\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"149.01037365484103\" x2=\"161.13610618692422\" y1=\"-1.3499999999999999\" y2=\"-1.3499999999999999\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"150.22280922013925\" x2=\"162.34854175222245\" y1=\"-0.6500000000000001\" y2=\"-0.6500000000000001\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"161.13610618692422\" x2=\"220.22937292666086\" y1=\"-1.35\" y2=\"-4.05\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"none\" stroke-width=\"1\" x1=\"162.34854175222245\" x2=\"220.22937292666086\" y1=\"1.3499999999999999\" y2=\"-4.05\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"193.41071957871353\" y=\"40.2\">maxpool2x2</text>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"193.41071957871353\" y=\"54.2\">stride (2, 2)</text>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"262.81106550258596\" y=\"143.59017020308966\">flatten</text>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"2\" stroke-width=\"1\" x1=\"291.81106550258596\" x2=\"341.81106550258596\" y1=\"-119.59017020308964\" y2=\"-6.964404506368992\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"2\" stroke-width=\"1\" x1=\"291.81106550258596\" x2=\"341.81106550258596\" y1=\"119.59017020308964\" y2=\"-6.964404506368992\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"316.81106550258596\" y=\"143.59017020308966\">dense</text>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"2\" stroke-width=\"1\" x1=\"345.81106550258596\" x2=\"395.81106550258596\" y1=\"-13.928809012737984\" y2=\"-0.9952679263837431\"/>\n<line stroke=\"rgb(0, 0, 255)\" stroke-dasharray=\"2\" stroke-width=\"1\" x1=\"345.81106550258596\" x2=\"395.81106550258596\" y1=\"13.928809012737984\" y2=\"-0.9952679263837431\"/>\n<text fill=\"rgb(0, 0, 0)\" font-family=\"arial\" font-size=\"14px\" text-anchor=\"middle\" x=\"370.81106550258596\" y=\"37.928809012737986\">dense</text>\n</svg>"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI4UDcU60bH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの学習方法について指定しておく\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s80FRVRL0bH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "a9bf3032-faa3-4273-9721-99f93604627f"
      },
      "source": [
        "# TensorBoardでの可視化のため、出力先の設定\n",
        "import os, shutil\n",
        "if os.path.exists(\"./logs\"):\n",
        "    shutil.rmtree(\"./logs\")\n",
        "\n",
        "from tensorflow.keras import callbacks\n",
        "#tb_cb = callbacks.TensorBoard(log_dir=\"./logs/\", histogram_freq=1,write_images=1,write_grads=True,embeddings_freq=1)\n",
        "tb_cb = callbacks.TensorBoard(log_dir=\"./logs/\", histogram_freq=1,write_images=1)\n",
        "cbks = [tb_cb]\n",
        "\n",
        "# モデルのサマリ情報の表示\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               2359552   \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,380,938\n",
            "Trainable params: 2,380,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_yBnQiN0bID",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.2 モデルの学習\n",
        "\n",
        "1.2.1で構築したモデルで実際に学習を行うには、Sequential.fit関数を用います。この関数は固定長のバッチで学習を行います。\n",
        "\n",
        "主な引数は次の通りです。\n",
        "\n",
        "* x：学習に使用する入力データ\n",
        "* y：学習に使用する出力データ\n",
        "* batch_size：学習中のパラメータ更新を1回行うにあたって用いるサンプル数（ミニバッチのサイズ）\n",
        "* epochs：学習のエポック数\n",
        "* verbose：学習のログを出力するか（0:しない、1：バーで出力、2:エポックごとに出力）\n",
        "* validation_split/validation_data：検証用に用いるデータの割合（0～１の実数）、または検証用データそのもの（いずれかのみ指定可能）\n",
        "* shuffle：各エポックごとにデータをシャッフルするか\n",
        "* callbacks：訓練中のモデルの挙動を監視できるcallback関数を指定できます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "_IQUEb790bIE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "outputId": "54c4e21b-3c71-49d2-c55c-5fcd0836c39b"
      },
      "source": [
        "#model.fit(x_train, y_train,\n",
        "#          batch_size=1000, epochs=10, verbose=1,\n",
        "#          validation_data=(x_test, y_test))\n",
        "#print(y_test.shape)\n",
        "epochs=20\n",
        "result = model.fit(x_train, y_train,\n",
        "          batch_size=1000, epochs=epochs, verbose=1,callbacks=cbks,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 36s 607us/sample - loss: 7.8446 - acc: 0.4329 - val_loss: 0.3340 - val_acc: 0.9031\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 32s 539us/sample - loss: 0.2149 - acc: 0.9359 - val_loss: 0.1435 - val_acc: 0.9585\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 32s 525us/sample - loss: 0.1246 - acc: 0.9625 - val_loss: 0.1046 - val_acc: 0.9707\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 32s 531us/sample - loss: 0.0914 - acc: 0.9730 - val_loss: 0.0851 - val_acc: 0.9750\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 32s 541us/sample - loss: 0.0727 - acc: 0.9788 - val_loss: 0.0739 - val_acc: 0.9786\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 32s 530us/sample - loss: 0.0611 - acc: 0.9820 - val_loss: 0.0667 - val_acc: 0.9789\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 32s 540us/sample - loss: 0.0518 - acc: 0.9847 - val_loss: 0.0639 - val_acc: 0.9795\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 32s 542us/sample - loss: 0.0451 - acc: 0.9869 - val_loss: 0.0599 - val_acc: 0.9812\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 32s 525us/sample - loss: 0.0390 - acc: 0.9889 - val_loss: 0.0550 - val_acc: 0.9825\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 32s 538us/sample - loss: 0.0338 - acc: 0.9906 - val_loss: 0.0537 - val_acc: 0.9830\n",
            "Epoch 11/20\n",
            "59000/60000 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9919"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-56824ea38181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m result = model.fit(x_train, y_train,\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m           validation_in_fit=True)\n\u001b[0m\u001b[1;32m    365\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCLIozIF0bIJ",
        "colab_type": "text"
      },
      "source": [
        "モデルの評価を行うには、Sequential.evaluate関数を用います。この関数は固定長のバッチごとに損失関数値または評価関数値を出力します。\n",
        "\n",
        "主な引数は次の通りです。\n",
        "\n",
        "* x：評価に使用する入力データ\n",
        "* y：評価に使用する出力データ\n",
        "* batch_size：1回の評価を行うにあたって用いるサンプル数\n",
        "* verbose：評価のログを出力するか（0:しない、1：する(デフォルト)）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys0GtCR60bIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB8isRg_hfGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result.history.keys() # ヒストリデータのラベルを見てみる\n",
        "plt.plot(range(1, epochs+1), result.history['acc'], label=\"training\")\n",
        "plt.plot(range(1, epochs+1), result.history['val_acc'], label=\"validation\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.xlim([1,epochs])\n",
        "plt.ylim([0,1])\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq7fmArk0bIN",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.3 モデルによる予測\n",
        "\n",
        "1.2.2で学習させたモデルによって予測を行ってみましょう。Sequential.predict関数によって予測が行えます。\n",
        "\n",
        "主な引数は次の通りです。\n",
        "\n",
        "* x_test：予測に使用する入力データ\n",
        "* batch_size：まとめて1度に予測を行うサンプル数\n",
        "* verbose：評価のログを出力するか（0:しない(デフォルト)、1：する）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7CJSTL50bIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = model.predict(x_test, batch_size=128, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sTY0plvOe-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データセットの推論結果と元画像を確認\n",
        "# test_numを0～9999で指定してください\n",
        "test_num=1001\n",
        "test_img = np.squeeze(x_test[test_num])\n",
        "if not model_structure==\"CNN\":\n",
        "    test_img = test_img.reshape(28, 28).astype(np.float32)\n",
        "\n",
        "print(test_img)\n",
        "test_img = 255 - test_img\n",
        "\n",
        "print(\"推論結果：\"+str(classes[test_num].argmax()))\n",
        "plt.imshow(test_img,'gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B2-3A2nVfuj",
        "colab_type": "text"
      },
      "source": [
        "自分で手書きした画像を推論させてみましょう。\n",
        "\n",
        "手書きファイルをアップロードし、ファイル名を指定して実行します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ8gMryWuxfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# サンプルデータのダウンロード\n",
        "!wget https://raw.githubusercontent.com/scpepper69/dl4us/master/lesson1/mnist.zip\n",
        "!unzip mnist.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDEx3_iRNpGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "    \n",
        "# Google Colabにファイルをアップロード\n",
        "# アップロードしたファイルを指定\n",
        "img_path=\"./four001.png\"\n",
        "img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
        "plt.imshow(img,'gray')\n",
        "\n",
        "img = 255 - img #白黒反転\n",
        "img = cv2.resize(img, dsize=(28,28)) # 28 x 28にサイズ変更\n",
        "img = img.astype(np.float32)\n",
        "print(img)\n",
        "\n",
        "if model_structure==\"CNN\":\n",
        "    img = img.reshape(1, 28, 28 ,1) # 2次元から4次元に変換\n",
        "else:    \n",
        "    img = img.reshape(1, 784).astype(np.float32)\n",
        "\n",
        "pred = model.predict(img,verbose=1)\n",
        "\n",
        "# 推論処理\n",
        "print(\"推論結果：\"+str(pred.argmax()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVxresNopyLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# 中間層の特徴マップを出力する\n",
        "def middle_layer_output(numlay, INPDATA):\n",
        "    get_layer = K.function([model.layers[0].input], [model.layers[numlay].output])\n",
        "    layer_output_comp = get_layer([INPDATA])[0]\n",
        "    if layer_output_comp.ndim == 4:\n",
        "        dim_n = layer_output_comp.shape[0]\n",
        "        dim_x = layer_output_comp.shape[1]\n",
        "        dim_y = layer_output_comp.shape[2]\n",
        "        dim_z = layer_output_comp.shape[3]\n",
        "    else:\n",
        "        dim_n = layer_output_comp.shape[0]\n",
        "        dim_z = layer_output_comp.shape[1]\n",
        "\n",
        "    #中間層の出力を図化する\n",
        "    plt.figure()\n",
        "    for num_pic in range(dim_n):\n",
        "        if layer_output_comp.ndim == 4:\n",
        "            for num_map in range(dim_z):\n",
        "                img = layer_output_comp[num_pic, :, :, num_map]\n",
        "                img = Image.fromarray(np.uint8(img))\n",
        "                plt.subplot(8,8,num_map+1)\n",
        "                plt.axis('off')\n",
        "                plt.imshow(img, cmap='gray')\n",
        "    \n",
        "        else:\n",
        "#            dims = int(np.sqrt(len(layer_output_comp[0])))\n",
        "            dims = int(len(layer_output_comp[0]))\n",
        "            img = layer_output_comp[num_pic, :]\n",
        "#            img = img.reshape(dims, dims).astype(np.float32)\n",
        "            img = img.reshape(dims, 1).astype(np.float32)\n",
        "            plt.axis('off')\n",
        "            plt.imshow(img, cmap='gray')\n",
        "\n",
        "# レイヤーごとの特徴マップの出力\n",
        "for layers in range(len(model.layers)-2):\n",
        "    middle_layer_output(layers, img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIXwHVGJ0bIP",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.4 モデルの可視化\n",
        "\n",
        "1.1.1で作成したモデルをTensorBoardをにて参照してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyx_anHq0bIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Web参照のため、ngrokを利用\n",
        "if not os.path.exists('./ngrok'):\n",
        "    !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "    !unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# TensorBoardおよびngrokの起動\n",
        "import subprocess\n",
        "cmd = \"tensorboard --logdir=./logs --host 0.0.0.0 --port 6006 &\"\n",
        "proc_tb = subprocess.call(cmd, shell=True)\n",
        "\n",
        "cmd = \"./ngrok http 6006 &\"\n",
        "proc_ng = subprocess.call(cmd, shell=True)\n",
        "\n",
        "# TensorBoard URL\n",
        "!curl -s http://localhost:4040/api/tunnels | python -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH37JEOU0bIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorBoardプロセスの停止\n",
        "#!ps -ef | grep tensorboard | grep -v grep | awk '{print \"kill -9\",$2}'| sh\n",
        "\n",
        "# ngrokプロセスの停止\n",
        "#!ps -ef | grep ngrok | grep -v grep | awk '{print \"kill -9\",$2}'| sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP3EQso80bIX",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 各モデルLayer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "mBI02lgi0bIY",
        "colab_type": "text"
      },
      "source": [
        "ここからは、layerクラスについて詳しくみていきましょう。\n",
        "\n",
        "MLPで中心的な存在である、層を表すクラスがlayerクラスです。\n",
        "\n",
        "layerには様々な種類があり、そのそれぞれが独自の機能を持っているので、役割をある程度覚えておきましょう。\n",
        "\n",
        "今回は最もオーソドックスなlayerとして、keras.layers.core以下に定義されている中で使用頻度の高いものを紹介します。\n",
        "\n",
        "https://keras.io/ja/layers/about-keras-layers/\n",
        "\n",
        "https://keras.io/ja/layers/core/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN8uh6OD0bIZ",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1 Dense\n",
        "\n",
        "一般的な全結合層を表すレイヤーです。つまり、入力$u\\in\\mathbb{R}^D$に対して、\n",
        "\n",
        "$v = \\sigma(Wu+b) \\in\\mathbb{R}^{D'}$\n",
        "\n",
        "を出力します。\n",
        "\n",
        "なお、$W\\in\\mathbb{R}^{D' \\times D}$は重み行列を表し、$b\\in\\mathbb{R}^{D'}$はバイアスを表しています。\n",
        "\n",
        "重み行列とバイアスは学習によって値が決まることに注意しましょう。\n",
        "\n",
        "また$\\sigma(x):\\mathbb{R}^{D'}\\to\\mathbb{R}^{D'}$は**活性化関数**と呼ばれるもので、任意に指定可能です。\n",
        "\n",
        "（実際には最後の出力層の活性化関数については問題の特性から決まることも多いです）\n",
        "\n",
        "一般に活性化関数には非線形関数を指定することで、MLPの性能を向上させます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBqWuwzq0bIZ",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "keras.layers.core.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
        "                        kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
        "                        kernel_constraint=None, bias_constraint=None)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY0pofdt0bIa",
        "colab_type": "text"
      },
      "source": [
        "主な引数は\n",
        "\n",
        "* units: 出力ユニット数($N$)\n",
        "* activation: 出力ユニットに適用する活性化関数、Activationレイヤーの説明を参照\n",
        "* use_bias: バイアス$b$を使用するか\n",
        "* kernel_initializer: 重み行列$W$の初期化方法（initializerについては3章で扱います）\n",
        "* bias_initializer: バイアス$b$の初期化方法（initializerについては3章で扱います）\n",
        "\n",
        "です。またshapeの入出力での変化は\n",
        "\n",
        "<ol>(batch_size, ..., input_dim) --> (batch_size, ..., units)</ol>\n",
        "\n",
        "のとおり、一番深いネストの次元がinput_dimからunitsに変わるだけです。\n",
        "\n",
        "1.1.1のモデルの構築で出てきた例を以下に再掲します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJvncM_u0bIa",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "model.add(Dense(units=256, input_shape=(784,))) # 次元の変化: 784 -> 256\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(units=100)) # 次元の変化: 256 -> 100\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(units=10)) # 次元の変化: 100 -> 10\n",
        "model.add(Activation('softmax'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2auB_GX0bIb",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2 Activation\n",
        "\n",
        "入力に対して活性化関数を適用したものを出力します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqGENA-u0bIc",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "keras.layers.core.Activation(activation)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt8mkQnU0bId",
        "colab_type": "text"
      },
      "source": [
        "引数は\n",
        "\n",
        "* activation: 適用する活性化関数\n",
        "\n",
        "のみです。（入力と出力でshapeは変わりません）\n",
        "\n",
        "活性化関数として使用できる関数の一覧はこちら( https://keras.io/ja/activations/ )です。\n",
        "\n",
        "よく使用されるものを以下に示します。\n",
        "\n",
        "* sigmoid: $f(x)=\\dfrac{1}{1+e^{-x}}$\n",
        "* ReLU: $f(x)=\\max(0,x)$\n",
        "* tanh: $f(x)=\\tanh(x)=\\dfrac{e^x-e^{-x}}{e^x+e^{-x}}$\n",
        "* softmax: $f(x)=\\dfrac{\\exp(x_d)}{\\sum_{d'} \\exp(x_{d'})} \\quad (x\\in\\mathbb{R}^D,\\ d=1,2,\\ldots,D)$\n",
        "\n",
        "特にsoftmax関数は出力が規格化されているので、確率として解釈できるため多クラス分類タスクの出力層に使用されることが多いです。\n",
        "\n",
        "（2クラス分類であればsigmoid関数を出力層に使用することも多いです）\n",
        "\n",
        "ここで、活性化関数をプロットしてみましょう。(多変数関数のsoftmaxを除く)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-tULG5p0bId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1+np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "fig = plt.figure()\n",
        "x = np.linspace(-10, 10, 1000)\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(x, sigmoid(x), label='sigmoid')\n",
        "ax.plot(x, relu(x), label='ReLU')\n",
        "ax.plot(x, tanh(x), label='tanh')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlim(-5, 5)\n",
        "plt.ylim(-1.1, 2)\n",
        "plt.grid(which='major',color='gray',linestyle='-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deHEnYOR0bIh",
        "colab_type": "text"
      },
      "source": [
        "1.1.1のモデルの構築で出てきた例を以下に再掲します。\n",
        "\n",
        "```py\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "model.add(Dense(units=256, input_shape=(784,)))\n",
        "model.add(Activation('relu')) # 活性化関数として relu を選択\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation('relu')) # 活性化関数として relu を選択\n",
        "model.add(Dense(units=10))\n",
        "model.add(Activation('softmax')) # 活性化関数として softmax を選択\n",
        "```\n",
        "\n",
        "なお、活性化関数はDenseレイヤーなどで直接指定することも可能で、実際に以下のコードは上記と同じ結果になります。\n",
        "\n",
        "```py\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "model.add(Dense(256, input_shape=(784,), activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYfUF8xS0bIh",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.3 Flatten\n",
        "\n",
        "入力をフラット化します。つまり、リストの入れ子になっているデータを1つのリストに展開します。\n",
        "\n",
        "(Ex. [[1,2,3],[4,5,6],[7],[8,9]]->[1,2,3,4,5,6,7,8,9])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_aoflDN0bIi",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "keras.layers.core.Flatten()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSZWJUX40bIj",
        "colab_type": "text"
      },
      "source": [
        "例は次の通りです。（出力shapeはbatch_sizeを除く入力shapeの積）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9jK50yV0bIj",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), input_shape=(3, 32, 32))) # 次元の変化: (3, 32, 32) -> (64, 32, 32)\n",
        "# Conv2Dは未修ですが、ここではその機能は関係ないので気にしなくて結構です\n",
        "\n",
        "model.add(Flatten()) # 次元の変化: (64, 32, 32) -> (65536,) (65536 = 64*32*32)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYY9lzSH0bIk",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.4 Reshape\n",
        "\n",
        "入力を指定のshapeに変換して出力します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPX796mW0bIl",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "keras.layers.core.Reshape(target_shape)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei7rOqVE0bIl",
        "colab_type": "text"
      },
      "source": [
        "引数は\n",
        "* target_shape: 変換先のshapeを表す整数のタプル、ただしサンプルの次元（バッチサイズ）を含まない\n",
        "\n",
        "例は次の通りです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRui-nh80bIm",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "model = Sequential()\n",
        "model.add(Reshape((3, 4), input_shape=(12,))) # 次元の変化: (12,) -> (3, 4)\n",
        "\n",
        "model.add(Reshape((6, 2))) # 次元の変化: (3, 4) -> (6, 2)\n",
        "\n",
        "# `-1`をしていすると、その次元については推定してくれます(6/2=3)\n",
        "model.add(Reshape((-1, 2, 2))) # 次元の変化: (6, 2) -> (?, 2, 2)=(3, 2, 2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucQ7uJRM0bIm",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.5 Permute\n",
        "\n",
        "入力の次元を入れ替えます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VngIwkch0bIn",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "keras.layers.core.Permute(dims)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvjF9_0E0bIo",
        "colab_type": "text"
      },
      "source": [
        "引数は\n",
        "\n",
        "* dims: 次元の入れ替え方を指定する整数のタプル、サンプルの次元はふくまない1から始まるindexで指定\n",
        "\n",
        "です。（入力と出力でshapeは変わりません）\n",
        "\n",
        "例は次の通りです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDR5EyED0bIp",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "model = Sequential()\n",
        "model.add(Permute((2, 1), input_shape=(10, 64))) # 次元の変化: (10, 64) -> (64, 10)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W67nYpg0bIr",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.6 RepeatVector\n",
        "\n",
        "入力を指定回数繰り返します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtMC1sJV0bIr",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "keras.layers.core.RepeatVector(n)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd8GrtJI0bIs",
        "colab_type": "text"
      },
      "source": [
        "引数は\n",
        "\n",
        "* n: 入力の複製回数\n",
        "\n",
        "です。またshapeの入出力での変化は\n",
        "\n",
        "<ol>(num_samples, features) --> (num_samples, n, features)</ol>\n",
        "\n",
        "であり、入力には2階のテンソルのみを受け付けます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F18fL6Cx0bIt",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 損失関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ36NEcz0bIv",
        "colab_type": "text"
      },
      "source": [
        "モデルの学習にあたっては、損失関数の最小化を行うわけでした。そこで、続いて損失関数についてみていきます。\n",
        "\n",
        "https://keras.io/ja/losses/\n",
        "\n",
        "kerasではモデルをコンパイルする際に損失関数を設定します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JbXxomQ0bIw",
        "colab_type": "text"
      },
      "source": [
        "損失関数の選択においては、出力値が連続な場合と離散な場合で大きく異なってきます。\n",
        "\n",
        "#### 連続値のとき\n",
        "\n",
        " 主に使用されるのは**平均二乗誤差**です。これは各ミニバッチのデータ数を$N$として、\n",
        "\n",
        " $$E=\\dfrac{1}{N}\\sum_{n=1}^{N}(y_n-t_n)^2$$\n",
        "\n",
        " として表されます。(なお、$y_n, t_n$はそれぞれ入力$x_n$に対するモデルの出力値(y_pred)と出力データ(y_true)を表す)\n",
        "\n",
        " この平均二乗誤差を使用する場合、compile関数の引数として`loss='mean_squared_error'`を指定します。\n",
        "\n",
        "\n",
        "#### 離散値のとき\n",
        "\n",
        "主に使用されるのは、**（多クラス）交差エントロピー**です。2クラス分類の場合は交差エントロピーとして\n",
        "\n",
        "$$E=-\\dfrac{1}{N}\\sum_{n=1}^N \\left[t_n \\ln y_n + (1-t_n) \\ln (1-y_n) \\right]$$\n",
        "\n",
        "を使用し、多クラス分類（Kクラス）の場合は多クラス交差エントロピーとして\n",
        "\n",
        "$$E=-\\dfrac{1}{N}\\sum_{n=1}^N \\sum_{k=1}^K t_{nk} \\ln y_{nk}$$\n",
        "\n",
        "を用います。それぞれcompile関数の引数として`loss='binary_crossentropy'`、`loss='categorical_crossentropy'`を指定することで使用できます。\n",
        "    \n",
        "\n",
        "今回利用したMNISTは0~9の離散値であるため、以下のように多クラス交差エントロピーを利用しています。\n",
        "\n",
        "```py\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBYBfyw90bIx",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 評価関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEWYC4ua0bIy",
        "colab_type": "text"
      },
      "source": [
        "評価関数(metric)はモデルの出力の良し悪しを評価します。\n",
        "\n",
        "損失関数もモデルの良し悪しの指標となるという点では同じですが、損失関数は最適化計算をとおして学習に直接的に影響するのに対して、評価関数は学習には使用されず、あくまでその時点でのモデルの評価指標を出力するのみであるという違いがあります。\n",
        "\n",
        "つまり、compile関数で指定すると、訓練やテストの際に参考情報として評価関数の値が返り値として受け取れるというだけです。\n",
        "\n",
        "評価関数として使用することが多いのは**accuracy(正解率)**です。（正解率＝全体のデータに対して予測値が答えと一致した割合）\n",
        "\n",
        "これはcompile関数の引数として、`metrics=['acc']`を指定することで使用できます。（リストに他の損失関数を含めれば、それらも同時に評価されます）\n",
        "\n",
        "https://keras.io/ja/metrics/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kDw9ZBi0bIz",
        "colab_type": "text"
      },
      "source": [
        "### 1.5 Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKNk1bRK0bIz",
        "colab_type": "text"
      },
      "source": [
        "ここまではkeras.models.Sequentialクラスを用いたモデル構築を説明しました。\n",
        "\n",
        "Sequentialクラスを用いる場合はadd関数を使用して簡単にモデルを構築できますが、途中に分岐や合流があるような複雑なモデルは作成できません。\n",
        "\n",
        "こうしたより複雑なモデルの構築には別の方法が用意されています。それが**Functional API**です。この特徴は\n",
        "\n",
        "* **Inputレイヤー**から構築を始める\n",
        "* 各レイヤーの返り値（テンソル）を次のレイヤーの入力として順々に構築していく\n",
        "* **keras.models.Modelクラス**に入力と出力を指定することでインスタンス化\n",
        "\n",
        "という点です。一度Modelクラスのインスタンスを作ってしまえば、後の学習等はSequentialクラスによる場合と同様です。\n",
        "\n",
        "より詳しくは、実際にFunctional APIが必須になる第4回で扱いますが、すぐにFunctional APIの発展的な利用法をみたいという方は、\n",
        "\n",
        "下記の公式HPのリンクにいくつか記載がありますので参考にしてみてください。\n",
        "\n",
        "https://keras.io/ja/getting-started/functional-api-guide/\n",
        "\n",
        "https://keras.io/ja/models/model/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKmaNCMW0bI2",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 確認問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjyPeDPG0bI3",
        "colab_type": "text"
      },
      "source": [
        "1. 学習データ以外の未知のデータに対するモデルの予測性能を何というか  \n",
        "  ①神通力　②バイアス　③汎化性能　④共起性\n",
        "2. データセット全体を一度に全て使用して学習する方法を何というか  \n",
        "  ①転移学習　②ワンショット学習　③過学習　④バッチ学習　\n",
        "3. 名義尺度のデータをバイナリベクトルによって表現したものを何というか  \n",
        "  ①分散表現　②one-hot表現　③ビット表現　④ユニタリ表現\n",
        "4. モデルの学習に当たって最小化するものは何か  \n",
        "  ①精度　②損失関数　③スコア　④F値"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RKTQVB80bI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}