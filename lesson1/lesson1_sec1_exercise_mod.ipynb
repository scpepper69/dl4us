{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson1_sec1_exercise_mod.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYOnZhT30bGu",
        "colab_type": "text"
      },
      "source": [
        "# Lesson1 手書き文字認識をしよう（ニューラルネットワーク入門）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ju7RayK0bGy",
        "colab_type": "text"
      },
      "source": [
        "## 目次\n",
        "\n",
        "- Section1 解説\n",
        "  - 1.1 Keras実装プロセス\n",
        "  - 1.2 各モデルLayer\n",
        "  - 1.3 損失関数\n",
        "  - 1.4 評価関数\n",
        "  - 1.5 Functional API\n",
        "  - 1.6 確認問題\n",
        "- Section2 実装①\n",
        "  - 2.1 MNISTによるMLPの復習\n",
        "- Section3 テクニック・発展内容\n",
        "  - 3.1 前処理\n",
        "  - 3.2 勾配に関するテクニック\n",
        "    - 3.2.1 最適化アルゴリズム (optimizer)\n",
        "    - 3.2.2 活性化関数 (activation)\n",
        "    - 3.2.3 初期化 (initializer)\n",
        "  - 3.3 過学習に関するテクニック\n",
        "    - 3.3.1 正則化 (regularization)\n",
        "    - 3.3.2 早期終了 (early stopping)\n",
        "    - 3.3.3 ドロップアウト (dropout)\n",
        "  - 3.4 確認問題\n",
        "- Section4 実装②\n",
        "  - 4.1 Fashion MNIST\n",
        "  - 4.2 実装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pNejt1B0bG1",
        "colab_type": "text"
      },
      "source": [
        "## Section1 解説"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2n0HLjd0bG3",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Keras実装プロセス"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVNVVU2o0bG5",
        "colab_type": "text"
      },
      "source": [
        "今回は早速KerasでMLPの実装方法を見ていきたいと思います。\n",
        "\n",
        "まず、Kerasの雰囲気を感じ取ってもらうため、Kerasで機械学習を行う際に、\n",
        "\n",
        "1. いったいどういった手順を踏むか\n",
        "2. コードはどう書くのか\n",
        "\n",
        "をざっくりと見ていきたいと思います。\n",
        "\n",
        "題材としては、手書き数字画像を入力データ、対応する数字の値を出力データとする教師あり学習（分類）です。\n",
        "\n",
        "参考：https://keras.io/ja/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFKVp80t0bG8",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.0 データの用意\n",
        "まず機械学習を適用するデータを用意しなければ始まりません。\n",
        "\n",
        "ここでは、機械学習で頻繁に用いられる、MNISTの手書き数字データセットを用います。\n",
        "\n",
        "データセットの中身は、\n",
        "\n",
        "* x:手書き数字画像(28×28)\n",
        "* y:正解のラベル（xの画像が表す数字）\n",
        "\n",
        "となっていますが、\n",
        "\n",
        "* (x_train, y_train):モデルの学習用\n",
        "* (x_test, y_test):モデルの評価用\n",
        "\n",
        "と区別してあります。\n",
        "\n",
        "機械学習では汎化性能の向上が至上命題なので、学習用のデータだけでなく評価用のデータが必要になることは前回触れました。\n",
        "\n",
        "MNISTのデータセットも、全てのデータを使用するのではなく、学習用と評価用に予め分割してあるわけです。\n",
        "\n",
        "（分割は事前に行っておく必要があります。評価用のデータまで使用して学習を行うのは、カンニングと変わらなくなってしまいます。）\n",
        "\n",
        "なお、KerasではこのMNISTのデータセットに限らず、機械学習で頻繁に用いられるデータセットがいくつも用意されており、性能評価を手軽に行えます。\n",
        "\n",
        "keras.datasets以下からimportすることで使用できますので、ぜひ使っていきましょう。\n",
        "\n",
        "Kerasから直接使用できるデータセットの一覧はこちら( https://keras.io/ja/datasets/ )です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIjKuxuD0bG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f92550ff-eb26-46ff-888a-8b15201808a4"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# MNISTデータセットをダウンロードし、変数にセット\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3pSTYqA0bHI",
        "colab_type": "text"
      },
      "source": [
        "今回扱うMNISTの手書き数字のデータを下記で表示してみましょう。\n",
        "\n",
        "表示する際には、matplotlibを用います。これはPythonでグラフの表示をする際に標準的に用いられるライブラリです。\n",
        "\n",
        "中でもpyplotは最もよく使用されるモジュールで、標準的な描画処理の多くに対応しています。\n",
        "\n",
        "ここでは詳しくは説明しませんが、公式のマニュアルでpyplotに含まれる関数に目を通しておくことをお勧めします。\n",
        "\n",
        "参考：https://matplotlib.org/api/pyplot_api.html\n",
        "\n",
        "なお、jupyer notebook上でmatplotlibの結果を表示するには、`%matplotlib inline`を冒頭で宣言する必要があります。\n",
        "\n",
        "（ちなみに、このような`%`あるいは`%%`から始まるjupyter notebookに対するコマンドはマジックコマンドと呼ばれ、他にも様々なものが存在します。）\n",
        "\n",
        "また、MNISTの画像には、それぞれに対して画像が示す数字が正解のラベルとして与えられています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-XaTkOc0bHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b197a59e-88df-494d-886c-a9cf7080c6a6"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(9, 15))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05, wspace=0.05)\n",
        "\n",
        "# 各MNIST画像の上に（タイトルとして）対応するラベルを表示\n",
        "for i in range(9):\n",
        "    ax = fig.add_subplot(1, 9, i + 1, xticks=[], yticks=[])\n",
        "    ax.set_title(str(y_train[i]))\n",
        "    ax.imshow(x_train[i], cmap='gray')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp0AAABmCAYAAACJHyrNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCRxuugUERERkcTpolNEREREEvf/CldH6Y/7NFcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 648x1080 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZCxZxgl0bHX",
        "colab_type": "text"
      },
      "source": [
        "これから、このMNISTの各画像が0～9のどの数字であるか分類する事を考えていきます。\n",
        "\n",
        "問題としては、いわゆる10クラス分類の問題です。（分類先のことを**クラス**と呼びます）\n",
        "\n",
        "さて、ここで特に分類タスクの際に気をつけたいことがあります。\n",
        "\n",
        "分類タスクの時の出力データはラベルですが、ラベルは数字としての大小には意味がないということです。\n",
        "\n",
        "というのも、グループの名前として数字を割り振っているだけであるためです。こうした数字を**名義尺度**と呼びます。\n",
        "\n",
        "機械学習のアルゴリズムでは数字の大小に意味があるものとして扱ってしまうため、名義尺度をうまく変換しなければなりません。\n",
        "\n",
        "この名義尺度を変換する表現として使用されるのが、**one-hot表現**と呼ばれるものです。\n",
        "\n",
        "全体で3クラスあるときの各クラスの表現は次の通りです。\n",
        "\n",
        "<ul>\n",
        "    <li>1：$[1,0,0]$</li>\n",
        "    <li>2：$[0,1,0]$</li>\n",
        "    <li>3：$[0,0,1]$</li>\n",
        "</ul>\n",
        "\n",
        "長さ3のベクトルを用いて、各クラスの対応する要素のみ1として表現するということです。\n",
        "\n",
        "一般化すると、全体で$K$クラスある時、$k$番目のクラスに属するとき、\n",
        "\n",
        "$\\underset{K}{\\underbrace{[0,\\cdots,0,\\overset{k}{\\check{1}},0,\\cdots,0]}}$\n",
        "\n",
        "と表現するということです。\n",
        "\n",
        "このone-hot表現への変換を行ってくれる関数がKerasにはあります。\n",
        "\n",
        "keras.utils.to_categorical関数がその関数です。さっそくMNISTのデータセットにも適用してみましょう。\n",
        "\n",
        "https://keras.io/ja/utils/#to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBvnPZCU0bHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# 入力画像を行列(28x28)からベクトル(長さ784)に変換\n",
        "#x_train = x_train.reshape(-1, 784)\n",
        "#x_test = x_test.reshape(-1, 784)\n",
        "# for CNN\n",
        "x_train = x_train.reshape(-1, 28, 28).astype(np.float32)\n",
        "x_test = x_test.reshape(-1, 28, 28).astype(np.float32)\n",
        "\n",
        "# 名義尺度の値をone-hot表現へ変換\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUUkN6qj0bHi",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.1 モデル構築\n",
        "\n",
        "学習に使用するMLPのモデルを構築します。具体的には、どんなlayer（層）をどこに配置するか、また各layerのユニット数はいくつかを指定していきます。\n",
        "\n",
        "このモデルを構築するための「容器」として機能するのが、keras.models.Sequentialクラスです。\n",
        "\n",
        "この「容器」の中に、Sequential.add関数によってkeras.layersに定義されているlayerクラス（後で詳述）を積み重ねていくことでモデルの構築を行います。\n",
        "\n",
        "layerをSequentialクラスに積み終えたら、最後にSequential.compile関数でモデルの学習処理について指定し、モデル構築は完了です。\n",
        "\n",
        "compile関数では\n",
        "\n",
        "* optimizer（最適化手法）\n",
        "* loss（損失関数）\n",
        "* metrics（評価関数（任意））\n",
        "\n",
        "を指定することになります。（いずれも後で詳述）\n",
        "\n",
        "https://keras.io/ja/models/sequential/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rIGYTTK0bHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデル構築用ライブラリをインポート\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "\n",
        "# CNNモデル用ライブラリ\n",
        "from tensorflow.python.keras.layers import Conv2D, Convolution2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.python.keras import initializers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ25Y8nL0bHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNNモデルの場合\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8TOq83u0bHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの「容器」を作成\n",
        "model = Sequential()\n",
        "\n",
        "# 「容器」へ各layer（Dense, Activation）を積み重ねていく（追加した順に配置されるので注意）\n",
        "# 最初のlayerはinput_shapeを指定して、入力するデータの次元を与える必要がある\n",
        "def classic():\n",
        "    model.add(Dense(units=256, input_shape=(784,)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(units=100))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(units=10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "# CNNモデルの場合\n",
        "def cnn_model():\n",
        "    model.add(Conv2D(32, (3, 3), kernel_initializer=initializers.TruncatedNormal(stddev=0.1), input_shape=(28,28,1)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), kernel_initializer=initializers.TruncatedNormal(stddev=0.1)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, kernel_initializer=initializers.TruncatedNormal(stddev=0.1)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units=10))\n",
        "    model.add(Activation('softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq7BxPyz0bH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "dfff7fe1-adca-48b8-c2b6-3f48858bfc7b"
      },
      "source": [
        "# model構築\n",
        "#classic()\n",
        "cnn_model()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI4UDcU60bH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの学習方法について指定しておく\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s80FRVRL0bH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "outputId": "c1904f00-cad4-4972-b30e-af67a5ee4659"
      },
      "source": [
        "# TensorBoardでの可視化のため、出力先の設定\n",
        "import os, shutil\n",
        "if os.path.exists(\"./logs\"):\n",
        "    shutil.rmtree(\"./logs\")\n",
        "\n",
        "from tensorflow.keras import callbacks\n",
        "#tb_cb = callbacks.TensorBoard(log_dir=\"./logs/\", histogram_freq=1,write_images=1,write_grads=True,embeddings_freq=1)\n",
        "tb_cb = callbacks.TensorBoard(log_dir=\"./logs/\", histogram_freq=1,write_images=1)\n",
        "cbks = [tb_cb]\n",
        "\n",
        "# モデルのサマリ情報の表示\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1 (Batc (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_1 (Ba (None, 11, 11, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               409856    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 431,626\n",
            "Trainable params: 431,434\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_yBnQiN0bID",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.2 モデルの学習\n",
        "\n",
        "1.2.1で構築したモデルで実際に学習を行うには、Sequential.fit関数を用います。この関数は固定長のバッチで学習を行います。\n",
        "\n",
        "主な引数は次の通りです。\n",
        "\n",
        "* x：学習に使用する入力データ\n",
        "* y：学習に使用する出力データ\n",
        "* batch_size：学習中のパラメータ更新を1回行うにあたって用いるサンプル数（ミニバッチのサイズ）\n",
        "* epochs：学習のエポック数\n",
        "* verbose：学習のログを出力するか（0:しない、1：バーで出力、2:エポックごとに出力）\n",
        "* validation_split/validation_data：検証用に用いるデータの割合（0～１の実数）、または検証用データそのもの（いずれかのみ指定可能）\n",
        "* shuffle：各エポックごとにデータをシャッフルするか\n",
        "* callbacks：訓練中のモデルの挙動を監視できるcallback関数を指定できます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "_IQUEb790bIE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "9f7550fe-e6c7-4d2e-8905-c79e6cac269a"
      },
      "source": [
        "#model.fit(x_train, y_train,\n",
        "#          batch_size=1000, epochs=10, verbose=1,\n",
        "#          validation_data=(x_test, y_test))\n",
        "epochs=10\n",
        "result = model.fit(x_train, y_train,\n",
        "          batch_size=1000, epochs=epochs, verbose=1,callbacks=cbks,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 28s 464us/sample - loss: 0.1687 - acc: 0.9485 - val_loss: 0.0859 - val_acc: 0.9742\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 28s 463us/sample - loss: 0.1669 - acc: 0.9490 - val_loss: 0.0847 - val_acc: 0.9749\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 28s 468us/sample - loss: 0.1652 - acc: 0.9501 - val_loss: 0.0824 - val_acc: 0.9755\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 28s 466us/sample - loss: 0.1628 - acc: 0.9513 - val_loss: 0.0803 - val_acc: 0.9758\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 28s 474us/sample - loss: 0.1588 - acc: 0.9520 - val_loss: 0.0789 - val_acc: 0.9765\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 28s 469us/sample - loss: 0.1524 - acc: 0.9536 - val_loss: 0.0786 - val_acc: 0.9767\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 29s 475us/sample - loss: 0.1487 - acc: 0.9538 - val_loss: 0.0765 - val_acc: 0.9774\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 28s 473us/sample - loss: 0.1488 - acc: 0.9552 - val_loss: 0.0758 - val_acc: 0.9771\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 28s 472us/sample - loss: 0.1444 - acc: 0.9551 - val_loss: 0.0739 - val_acc: 0.9778\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 28s 468us/sample - loss: 0.1432 - acc: 0.9562 - val_loss: 0.0735 - val_acc: 0.9786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCLIozIF0bIJ",
        "colab_type": "text"
      },
      "source": [
        "モデルの評価を行うには、Sequential.evaluate関数を用います。この関数は固定長のバッチごとに損失関数値または評価関数値を出力します。\n",
        "\n",
        "主な引数は次の通りです。\n",
        "\n",
        "* x：評価に使用する入力データ\n",
        "* y：評価に使用する出力データ\n",
        "* batch_size：1回の評価を行うにあたって用いるサンプル数\n",
        "* verbose：評価のログを出力するか（0:しない、1：する(デフォルト)）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys0GtCR60bIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "782daa53-3235-4052-a932-133f3d1b1882"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.07351776286941021\n",
            "Test accuracy: 0.9786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB8isRg_hfGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "dcae24c5-4d69-46f5-fc4c-c7c176950b3f"
      },
      "source": [
        "result.history.keys() # ヒストリデータのラベルを見てみる\n",
        "plt.plot(range(1, epochs+1), result.history['acc'], label=\"training\")\n",
        "plt.plot(range(1, epochs+1), result.history['val_acc'], label=\"validation\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.xlim([1,10])\n",
        "plt.ylim([0.8,1])\n",
        "plt.show()\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYXVWZ7/Hv75yqSiUhQEjClAQT\nbbqTMBikOmAjNOIUaAREFHCAcNW0NAri0MZ7bYE0ttjNtZUr4g0aBhukI8pgX5DJAPoIdioMgTAG\nRFJJgDAPCUmq6r1/7FWVXSeVyqmwT05V8vs8z3nOHtZa9e4DWe/Za++ztiICMzOzIpTqHYCZmW09\nnFTMzKwwTipmZlYYJxUzMyuMk4qZmRXGScXMzApT06Qiaa6k5yQ9uJH9knSBpCWSFkl6V27fyZIe\nT6+Tc9v3l/RAqnOBJNXyGMzMrHq1PlO5FJjex/7DgT3TayZwEYCknYCzgAOAacBZkkamOhcBn8vV\n66t9MzPbgmqaVCLiTuDFPoocDVwembuBHSXtBnwIuCUiXoyIl4BbgOlp3/YRcXdkv9q8HDimlsdg\nZmbVa6jz3x8LLM2tt6VtfW1v62X7BiTNJDv7Yfjw4ftPmjSpuKjNzLYBCxcufD4ixvSnTr2TSs1E\nxBxgDkBLS0u0trbWOSIzs8FF0p/7W6fed38tA8bn1selbX1tH9fLdjMzGwDqnVSuB05Kd4EdCLwS\nESuAm4APShqZLtB/ELgp7XtV0oHprq+TgOvqFr2ZmfVQ0+EvST8HDgVGS2oju6OrESAifgzcABwB\nLAFWAaekfS9K+mdgQWpqdkR0XfD/B7K7yoYCN6aXmZkNANoWpr73NRUzs/6TtDAiWvpTp97DX2Zm\nthVxUjEzs8I4qZiZWWGcVMzMrDBOKmZmVhgnFTMzK4yTipmZFcZJxczMCuOkYmZmhXFSMTOzwjip\nmJlZYZxUzMysME4qZmZWGCcVMzMrjJOKmZkVxknFzMwKU9MnP5qZ2SDQ2Qkda9Nr3frlzeCkYmZW\ntM6O9R10Z/v6jrpzHXS0p/e1ueV1PTvzQpb7sT86Cjv0Wj+jfjrwA6AM/CQizqvY/zZgLjAGeBH4\nVES0SXov8O+5opOAEyLiWkmXAn8LvJL2zYiI+2p5HGZ1E5G9CIjOtN7Z+3qPjix1XpvsyNau7/Ty\nndsG9Ss7x2rqtGexlUqg/Ku8frlUBqn3fSr1XXeT+5Xar9hP9Ix3Yx18j+Ne27861PAx7SpDuSm9\nGiveK5abhkN55Mb397ncCOd8ut/h1SypSCoDFwIfANqABZKuj4iHcsXOBy6PiMskHQZ8B/h0RMwH\npqZ2dgKWADfn6n0tIq6uVey2hXR1iF2vzo6e613beu3U+vjH3VsnUM23xM6K977qd8eY7+Sj706/\ne73KJBGd9fyvs14pdTBd793LDVkH1LVcSp1S07D1ZVWq4r9xH/s2Wjeyb9e97u/6LHvZ39XZlxp6\nOZ7GbHtX59q1XGqEhmYYMqLv4+6rfq9/p7LOkCo6/MYsUW4xAyipANOAJRHxJICkq4CjgXxSmQJ8\nOS3PB67tpZ3jgBsjYlUNY62tzo7ev+F1tqdOqr1G6x3rO9lNrrfn/lFW/mOs/Ade+Y8/eukQKv6B\n99Zh1PLbXJ9U8Q+64h93b51A4/Y9O4RSOWun6xuxSrl1KtYr9+fXtYn9VZZHmz6GTXVq3Z1jQ89y\nUp3+O9VApP/ntqZjGmBqmVTGAktz623AARVl7geOJRsi+wgwQtKoiHghV+YE4HsV9b4t6VvAbcCs\niFjTZySrX4J7/6P/45u9fvPdjPpbuvNUOddRlLMOorf1UkPqQFInUiqDGnPDEpVDC/lhh8r96mVo\notz3/mqGP1Sq7ttxv74lbslvejagOJnUXL0v1H8V+KGkGcCdwDKg+4qRpN2AfYCbcnW+ATwDNAFz\ngK8DsysbljQTmAmw/24luO60jUdRauj7G9wGp8JNMGS7Xjq2/Cl1Xx1bxd/r7uALWFc5G2c2M6uD\nWiaVZcD43Pq4tK1bRCwnO1NB0nbARyPi5VyRjwPXRMS6XJ0VaXGNpEvIEtMGImIOWdKhZeo+wRn/\ntfFvrv72YmZWiFomlQXAnpImkiWTE4BP5AtIGg28GBGdZGcgcyvaODFtz9fZLSJWSBJwDPDgJiNp\nGAIj37a5x2FmZlWq2ThJRLQDXyAbunoYmBcRiyXNlnRUKnYo8Kikx4BdgG931Zc0gexM546Kpq+Q\n9ADwADAaOLdWx2BmZv2jiHrdgbPltLS0RGtra73DMDMbVCQtjIiW/tTxFV0zMyuMk4qZmRXGScXM\nzArjpGJmZoVxUjEzs8I4qZiZWWGcVMzMrDBOKmZmVhgnFTMzK4yTipmZFcZJxczMCuOkYmZmhXFS\nMTOzwjipmJlZYer9OGEzM+uniGBtRydr2jtZs66TNe0dPZbfzG9r72TNutxyewdr1nXyZnrv3lbZ\nVnvnZsXmpGJmg8ba9k5Wr+tg9doOVq1tZ9XaDt5c18GqtR0Vy+2sXtvB6rS+em0Hq1K9tR1ZZynW\nP0k8WxZdDxbPtqtiP3SVkHquo/Vt9Czf1V4q2V1cPfYDWZLo0dlvmAjWtHfyZkoQb1VTQ4nmhhJD\nGssMaSilV5khjdnyjkMbN6tdJxWzbUhE0Bm5d4IIshc99xHQGUGQ3tO+/Pr67b3UJ1jbHqxe197d\nsa/eIAFsmBh6JoNUNyWE9s7+PVSwoSSGNpUZ1lRmaGOZoU0NNDWUuj6M7I318XdtztbXf2a54us/\ns9z+6Gqou73I7V9fp0c7ub8PbNCpDx/SwE7D07aGUtqeSwBdyWAjSWFIQ5nmxt7rN5VLlEr5lNa7\nyz/Tjw87cVIxq4OIYE17J2+syTrNN9a288aajrSeLa9a284baztYtSa957ev6aqT6q9pp70z19Gn\nv9Fzvd5HvaFySQxrLNOc6/iHNZUZ2lRm5LCmXDLItg9rKtPcWGZYU0N3uXydoWlfV/nGsi8bb2lO\nKmY5EUFHZ7CuI1jX2cm69k7aO4O16X1dRydr0xDE67kOvSsxrFpT8b62q9yG+6r90i3BsMYyw4c0\nMHxI1pkOb2pgp+FNjB85rLuzbUzfPruHcgSlNERTSuMxXevd+6TuYZxSGtIppSGcUncbqUwawilV\ntN21r5QbEura1lQWQ5saenT8+UTRVC51DxnZ1qGmSUXSdOAHQBn4SUScV7H/bcBcYAzwIvCpiGhL\n+zqAB1LRpyPiqLR9InAVMApYCHw6ItbW8jisOBFZh911MTEbH15/YXH9tvXv6zo6s06+o5P2jk7W\ndgTtHZXbs/d1nZESQR/lOjt71snt6xpv31wlwfCm1PkPyTr/YU1ldh7RzLBRaX3I+vfthjQwrKmB\n4U1lhg1J700NDB+y/r25oVzVUIXZQFCzpCKpDFwIfABoAxZIuj4iHsoVOx+4PCIuk3QY8B3g02nf\n6oiY2kvT3wX+PSKukvRj4DPARbU6jq1ZZ2dscHHwzfZsfLuyk6/s6PPvvZXvq2w/h8V71VASjeUS\nDWXRlN4by6X0Eg2lEo0NJRpTuebGjZQrZ+PLDSX1KN+Q9jf2qJPWS6UenX5X4hg+pIEhDf7mbdu2\nWp6pTAOWRMSTAJKuAo4G8kllCvDltDwfuLavBpX9az0M+ETadBlwNoM4qVR+c++646OrI97gbpBe\nbhnsreybGy27fnntW7yDpLmxRHNj9k16SGOJ5q4Lg41lRjQ3MGbEkLS/lNu//uJhV9khDamd7rLZ\nvq52N0gWZbnjNhugaplUxgJLc+ttwAEVZe4HjiUbIvsIMELSqIh4AWiW1Aq0A+dFxLVkQ14vR0R7\nrs2xvf1xSTOBmQCjxk7kh799nI5O6IigszPWv+eW2zuDzjSm3tHJ+uV82bTekSvbmdrt2tbeERvW\njVQuLa/rWH9P+Fv55i7Ro1PvuvOjOXXWw5pyd5Dk7v5oblx/R0hzbl9zrvPvkShySaC5seSxcDPr\nVb0v1H8V+KGkGcCdwDKgI+17W0Qsk/R24LeSHgBeqbbhiJgDzAEYstuecf7Nj3XvKym766QkUS6J\nskS5nL2XutZLolRig21dr3zdUgkaS6XubQ25/T3akyiXSGVK3d/0e3Ty+c5/I4kiX9bf2s1sIKll\nUlkGjM+tj0vbukXEcrIzFSRtB3w0Il5O+5al9ycl3Q7sB/wS2FFSQzpb2aDN3uy9+w7cde7hqWPH\nnbCZWY3U8ibuBcCekiZKagJOAK7PF5A0WlJXDN8guxMMSSMlDekqAxwEPBTZr4XmA8elOicD120q\nECn79Wi55G/1Zma1VLOkks4kvgDcBDwMzIuIxZJmSzoqFTsUeFTSY8AuwLfT9slAq6T7yZLIebm7\nxr4OfFnSErJrLD+t1TGYmVn/KAbiz2wL1tLSEq2trfUOw8xsUJG0MCJa+lPHcxiYmVlhnFTMzKww\nTipmZlYYJxUzMyuMk4qZmRXGScXMzArjpGJmZoVxUjEzs8I4qZiZWWGcVMzMrDBOKmZmVhgnFTMz\nK4yTipmZFcZJxczMCuOkYmZmhXFSMTOzwjipmJlZYZxUzMysMDVNKpKmS3pU0hJJs3rZ/zZJt0la\nJOl2SePS9qmS7pK0OO07PlfnUkl/knRfek2t5TGYmVn1apZUJJWBC4HDgSnAiZKmVBQ7H7g8IvYF\nZgPfSdtXASdFxF7AdOD7knbM1ftaRExNr/tqdQxmZtY/tTxTmQYsiYgnI2ItcBVwdEWZKcBv0/L8\nrv0R8VhEPJ6WlwPPAWNqGKuZmRWglkllLLA0t96WtuXdDxyblj8CjJA0Kl9A0jSgCXgit/nbaVjs\n3yUN6e2PS5opqVVS68qVK9/KcZiZWZXqfaH+q8DfSroX+FtgGdDRtVPSbsDPgFMiojNt/gYwCfhr\nYCfg6701HBFzIqIlIlrGjPFJjpnZltBQw7aXAeNz6+PStm5paOtYAEnbAR+NiJfT+vbA/wP+V0Tc\nnauzIi2ukXQJWWIyM7MBoJZnKguAPSVNlNQEnABcny8gabSkrhi+AcxN25uAa8gu4l9dUWe39C7g\nGODBGh6DmZn1Q82SSkS0A18AbgIeBuZFxGJJsyUdlYodCjwq6TFgF+DbafvHgUOAGb3cOnyFpAeA\nB4DRwLm1OgYzM+sfRUS9Y6i5lpaWaG1trXcYZmaDiqSFEdHSnzr1vlBvZmZbkU0mFUlflDRySwRj\nZmaDWzVnKrsACyTNS9OuqNZBmZnZ4LTJpBIR3wT2BH4KzAAel/Qvkt5R49jMzGyQqeqaSmRX859J\nr3ZgJHC1pH+tYWxmZjbIbPLHj5LOAE4Cngd+QjaZ47r0+5LHgX+sbYhmZjZYVPOL+p2AYyPiz/mN\nEdEp6cjahGVmZoNRNcNfNwIvdq1I2l7SAQAR8XCtAjMzs8GnmqRyEfB6bv31tM3MzKyHapKKIvez\n+zRbcC0nojQzs0GqmqTypKTTJTWm1xnAk7UOzMzMBp9qksrngb8hm7a+DTgAmFnLoMzMbHDa5DBW\nRDxHNm29mZlZn6r5nUoz8BlgL6C5a3tE/I8axmVmZoNQNcNfPwN2BT4E3EH2BMfXahmUmZkNTtUk\nlb+IiH8C3oiIy4C/I7uuYmZm1kM1SWVden9Z0t7ADsDOtQvJzMwGq2p+bzInPU/lm2TPmN8O+Kea\nRmVmZoNSn2cqadLIVyPipYi4MyLeHhE7R8T/rabx9PyVRyUtkTSrl/1vk3SbpEWSbpc0LrfvZEmP\np9fJue37S3ogtXmBn+9iZjZw9JlU0q/nN2sWYkll4ELgcGAKcKKkKRXFzgcuj4h9gdnAd1LdnYCz\nyK7dTAPOyj198iLgc2TPeNkTmL458ZmZWfGquaZyq6SvShovaaeuVxX1pgFLIuLJiFgLXAUcXVFm\nCvDbtDw/t/9DwC0R8WJEvATcAkyXtBuwfUTcnaaOuRw4popYzMxsC6jmmsrx6f203LYA3r6JemOB\npbn1rl/j590PHAv8APgIMELSqI3UHZtebb1s34CkmaRf/u+xxx6bCNXMzIpQzS/qJ9bw738V+KGk\nGcCdZFPBdBTRcETMAeYAtLS0xCaKm5lZAar5Rf1JvW2PiMs3UXUZMD63Pi5ty7exnOxMBUnbAR+N\niJclLQMOrah7e6o/rmJ7jzbNzKx+qrmm8te518HA2cBRVdRbAOwpaaKkJrL5w67PF5A0Ot1hBvAN\nYG5avgn4oKSR6QL9B4GbImIF8KqkA9NdXycB11URi5mZbQHVDH99Mb8uaUeyi+6bqtcu6QtkCaIM\nzI2IxZJmA60RcT3Z2ch3JAXZ8Ndpqe6Lkv6ZLDEBzI6IrqdP/gNwKTCU7KmUN24qFjMz2zKUe/5W\ndRWkRuDBiPir2oRUvJaWlmhtba13GGZmg4qkhRHR0p861VxT+TXZ3V6QDZdNAeb1PzwzM9vaVXNL\n8fm55XbgzxHRtrHCZma27aomqTwNrIiINwEkDZU0ISKeqmlkZmY26FRz99cvgM7cekfaZmZm1kM1\nSaUhTbMCQFpuql1IZmY2WFWTVFZK6v5diqSjgedrF5KZmQ1W1VxT+TxwhaQfpvU2sh8dmpmZ9VDN\njx+fAA5M06gQEa/XPCozMxuUNjn8JelfJO0YEa9HxOtp6pRzt0RwZmY2uFRzTeXwiHi5ayU93+SI\n2oVkZmaDVTVJpSxpSNeKpKHAkD7Km5nZNqqaC/VXALdJugQQMAO4rJZBmZnZ4FTNhfrvSrofeD/Z\nHGA3AW+rdWBmZjb4VDP8BfAsWUL5GHAY8HDNIjIzs0Fro2cqkv4SODG9ngf+k2yq/PduodjMzGyQ\n6Wv46xHgd8CREbEEQNKZWyQqMzMblPoa/joWWAHMl3SxpPeRXag3MzPr1UaTSkRcGxEnAJOA+cCX\ngJ0lXSTpg1sqQDMzGzw2eaE+It6IiCsj4sPAOOBe4OvVNC5puqRHJS2RNKuX/XtImi/pXkmLJB2R\ntn9S0n25V6ekqWnf7anNrn079+uIzcysZvr9jPqqG5bKwGPAB8gmoVwAnBgRD+XKzAHujYiLJE0B\nboiICRXt7ANcGxHvSOu3A1+NiKofOu9n1JuZ9d/mPKO+2luKN8c0YElEPJmewXIVcHRFmQC2T8s7\nAMt7aefEVNfMzAa4WiaVscDS3Hpb2pZ3NvApSW3ADcAXe2nneODnFdsuSUNf/ySp15sHJM2U1Cqp\ndeXKlZt1AGZm1j+1TCrVOBG4NCLGkU1S+TNJ3TFJOgBYFREP5up8MiL2AQ5Or0/31nBEzImIloho\nGTNmTO2OwMzMutUyqSwDxufWx6VteZ8B5gFExF1AMzA6t/8EKs5SImJZen8NuJJsmM3MzAaAWiaV\nBcCekiZKaiJLENdXlHkaeB+ApMlkSWVlWi8BHyd3PUVSg6TRabkROBJ4EDMzGxCqmaV4s0REu6Qv\nkE1AWQbmRsRiSbOB1oi4HvgKcHH6pX4AM2L97WiHAEsj4slcs0OAm1JCKQO3AhfX6hjMzKx/anZL\n8UDiW4rNzPpvoN1SbGZm2xgnFTMzK4yTipmZFcZJxczMCuOkYmZmhXFSMTOzwjipmJlZYZxUzMys\nME4qZmZWGCcVMzMrjJOKmZkVxknFzMwK46RiZmaFcVIxM7PCOKmYmVlhnFTMzKwwTipmZlYYJxUz\nMytMTZOKpOmSHpW0RNKsXvbvIWm+pHslLZJ0RNo+QdJqSfel149zdfaX9EBq8wJJquUxmJlZ9WqW\nVCSVgQuBw4EpwImSplQU+yYwLyL2A04AfpTb90RETE2vz+e2XwR8DtgzvabX6hjMzKx/anmmMg1Y\nEhFPRsRa4Crg6IoyAWyflncAlvfVoKTdgO0j4u6ICOBy4JhiwzYzs81Vy6QyFliaW29L2/LOBj4l\nqQ24Afhibt/ENCx2h6SDc222baJNACTNlNQqqXXlypVv4TDMzKxa9b5QfyJwaUSMA44AfiapBKwA\n9kjDYl8GrpS0fR/tbCAi5kRES0S0jBkzpvDAzcxsQw01bHsZMD63Pi5ty/sM6ZpIRNwlqRkYHRHP\nAWvS9oWSngD+MtUft4k2zcysTmp5prIA2FPSRElNZBfir68o8zTwPgBJk4FmYKWkMelCP5LeTnZB\n/smIWAG8KunAdNfXScB1NTwGMzPrh5qdqUREu6QvADcBZWBuRCyWNBtojYjrga8AF0s6k+yi/YyI\nCEmHALMlrQM6gc9HxIup6X8ALgWGAjeml5mZDQDKbqLaurW0tERra2u9wzAzG1QkLYyIlv7UqfeF\nejMz24o4qZiZWWGcVMzMrDBOKmZmVhgnFTMzK4yTipmZFcZJxczMCuOkYmZmhXFSMTOzwjipmJlZ\nYZxUzMysMLWc+n5AW7duHW1tbbz55pv1DmWr0NzczLhx42hsbKx3KGZWR9tsUmlra2PEiBFMmDCB\nbBZ921wRwQsvvEBbWxsTJ06sdzhmVkfb7PDXm2++yahRo5xQCiCJUaNG+azPzLbdpAI4oRTIn6WZ\nwTaeVMzMrFhOKnXy8ssv86Mf/ajf9Y444ghefvnlPst861vf4tZbb93c0MzMNpuTSp1sLKm0t7f3\nWe+GG25gxx137LPM7Nmzef/73/+W4jMz2xw1vftL0nTgB2TPqP9JRJxXsX8P4DJgx1RmVkTcIOkD\nwHlAE7AW+FpE/DbVuR3YDVidmvlgRDz3VuI859eLeWj5q2+liQ1M2X17zvrwXhvdP2vWLJ544gmm\nTp1KY2Mjzc3NjBw5kkceeYTHHnuMY445hqVLl/Lmm29yxhlnMHPmTAAmTJhAa2srr7/+Oocffjjv\nec97+MMf/sDYsWO57rrrGDp0KDNmzODII4/kuOOOY8KECZx88sn8+te/Zt26dfziF79g0qRJrFy5\nkk984hMsX76cd7/73dxyyy0sXLiQ0aNHF/o5mNm2pWZnKpLKwIXA4cAU4ERJUyqKfROYFxH7AScA\nXV/dnwc+HBH7ACcDP6uo98mImJpebymh1Mt5553HO97xDu677z7+7d/+jXvuuYcf/OAHPPbYYwDM\nnTuXhQsX0traygUXXMALL7ywQRuPP/44p512GosXL2bHHXfkl7/8Za9/a/To0dxzzz2ceuqpnH/+\n+QCcc845HHbYYSxevJjjjjuOp59+unYHa2bbjFqeqUwDlkTEkwCSrgKOBh7KlQlg+7S8A7AcICLu\nzZVZDAyVNCQi1tQi0L7OKLaUadOm9fiNxwUXXMA111wDwNKlS3n88ccZNWpUjzoTJ05k6tSpAOy/\n//489dRTvbZ97LHHdpf51a9+BcDvf//77vanT5/OyJEjCz0eM9s21TKpjAWW5tbbgAMqypwN3Czp\ni8BwoLcLAR8F7qlIKJdI6gB+CZwbEVFY1HUyfPjw7uXbb7+dW2+9lbvuuothw4Zx6KGH9vobkCFD\nhnQvl8tlVq9evUGZfLlyubzJazZmZm9FvS/UnwhcGhHjgCOAn0nqjknSXsB3gb/P1flkGhY7OL0+\n3VvDkmZKapXUunLlypodwOYaMWIEr732Wq/7XnnlFUaOHMmwYcN45JFHuPvuuwv/+wcddBDz5s0D\n4Oabb+all14q/G+Y2banlkllGTA+tz4ubcv7DDAPICLuApqB0QCSxgHXACdFxBNdFSJiWXp/DbiS\nbJhtAxExJyJaIqJlzJgxhRxQkUaNGsVBBx3E3nvvzde+9rUe+6ZPn057ezuTJ09m1qxZHHjggYX/\n/bPOOoubb76Zvffem1/84hfsuuuujBgxovC/Y2bbFtVq5EhSA/AY8D6yZLIA+ERELM6VuRH4z4i4\nVNJk4DayYbMdgDuAcyLiVxVt7hgRz0tqBH4O3BoRP+4rlpaWlmhtbe2x7eGHH2by5MkFHOngtGbN\nGsrlMg0NDdx1112ceuqp3HfffW+pzW39MzXb2khaGBEt/alTs2sqEdEu6QvATWS3C8+NiMWSZgOt\nEXE98BXgYklnkl20nxERker9BfAtSd9KTX4QeAO4KSWUMnArcHGtjmFr9vTTT/Pxj3+czs5Ompqa\nuPhif4xm9tbV7ExlIPGZypbhz9Rs67I5Zyr1vlBvZmZbEScVMzMrjJOKmZkVxknFzMwK46QySGy3\n3XYALF++nOOOO67XMoceeiiVNyRU+v73v8+qVau616uZSt/MrFpOKoPM7rvvztVXX73Z9SuTSjVT\n6ZuZVaumU98PGjfOgmceKLbNXfeBw8/b6O5Zs2Yxfvx4TjvtNADOPvtsGhoamD9/Pi+99BLr1q3j\n3HPP5eijj+5R76mnnuLII4/kwQcfZPXq1Zxyyincf//9TJo0qcfcX6eeeioLFixg9erVHHfccZxz\nzjlccMEFLF++nPe+972MHj2a+fPnd0+lP3r0aL73ve8xd+5cAD772c/ypS99iaeeemqjU+ybmVXy\nmUqdHH/88d1zbwHMmzePk08+mWuuuYZ77rmH+fPn85WvfIW+fkd00UUXMWzYMB5++GHOOeccFi5c\n2L3v29/+Nq2trSxatIg77riDRYsWcfrpp7P77rszf/585s+f36OthQsXcskll/DHP/6Ru+++m4sv\nvph7780mi652in0zM5+pQJ9nFLWy33778dxzz7F8+XJWrlzJyJEj2XXXXTnzzDO58847KZVKLFu2\njGeffZZdd9211zbuvPNOTj/9dAD23Xdf9t133+598+bNY86cObS3t7NixQoeeuihHvsr/f73v+cj\nH/lI92zJxx57LL/73e846qijqp5i38zMSaWOPvaxj3H11VfzzDPPcPzxx3PFFVewcuVKFi5cSGNj\nIxMmTOh1yvtN+dOf/sT555/PggULGDlyJDNmzNisdrpUO8W+mZmHv+ro+OOP56qrruLqq6/mYx/7\nGK+88go777wzjY2NzJ8/nz//+c991j/kkEO48sorAXjwwQdZtGgRAK+++irDhw9nhx124Nlnn+XG\nG2/srrOxKfcPPvhgrr32WlatWsUbb7zBNddcw8EHH1zg0ZrZtsBnKnW011578dprrzF27Fh22203\nPvnJT/LhD3+YffbZh5aWFiZNmtRn/VNPPZVTTjmFyZMnM3nyZPbff38A3vnOd7LffvsxadIkxo8f\nz0EHHdRdZ+bMmUyfPr372kqu0LgjAAAH8klEQVSXd73rXcyYMYNp07InCXz2s59lv/3281CXmfWL\nJ5S0wvgzNdu6eEJJMzOrKycVMzMrzDadVLaFob8txZ+lmcE2nFSam5t54YUX3BkWICJ44YUXaG5u\nrncoZlZn2+zdX+PGjaOtrY2VK1fWO5StQnNzM+PGjat3GGZWZ9tsUmlsbGTixIn1DsPMbKtS0+Ev\nSdMlPSppiaRZvezfQ9J8SfdKWiTpiNy+b6R6j0r6ULVtmplZ/dQsqUgqAxcChwNTgBMlTako9k1g\nXkTsB5wA/CjVnZLW9wKmAz+SVK6yTTMzq5NanqlMA5ZExJMRsRa4Cji6okwA26flHYDlaflo4KqI\nWBMRfwKWpPaqadPMzOqkltdUxgJLc+ttwAEVZc4Gbpb0RWA48P5c3bsr6o5Ny5tqEwBJM4GZaXWN\npAf7GX+tjQaer3cQFRxT9QZiXI6pOo6pen/V3wr1vlB/InBpRPxvSe8GfiZp7yIajog5wBwASa39\nnWqg1hxTdQZiTDAw43JM1XFM1ZPU9/PJe1HLpLIMGJ9bH5e25X2G7JoJEXGXpGayjN1X3U21aWZm\ndVLLayoLgD0lTZTURHbh/fqKMk8D7wOQNBloBlamcidIGiJpIrAn8N9VtmlmZnVSszOViGiX9AXg\nJqAMzI2IxZJmA60RcT3wFeBiSWeSXbSfEdlP3BdLmgc8BLQDp0VEB0BvbVYRzpyij68Ajqk6AzEm\nGJhxOabqOKbq9TuubWLqezMz2zK22bm/zMyseE4qZmZWmK06qUiaK+m5gfQbFUnj09Q0D0laLOmM\nARBTs6T/lnR/iumcesfUJc2kcK+k/6p3LACSnpL0gKT7Nud2y1qQtKOkqyU9IunhdHt+vWP6q/QZ\ndb1elfSlARDXmen/8Qcl/TzdcVrvmM5I8Syu12fUW18paSdJt0h6PL2PrKatrTqpAJeSblkeQNqB\nr0TEFOBA4LQBMNXMGuCwiHgnMBWYLunAOsfU5Qzg4XoHUeG9ETF1AP2u4AfAbyJiEvBOBsDnFRGP\nps9oKrA/sAq4pp4xSRoLnA60RMTeZDf7nFDnmPYGPkc2W8g7gSMl/UUdQrmUDfvKWcBtEbEncFta\n36StOqlExJ3Ai/WOIy8iVkTEPWn5NbIOYGzftWoeU0TE62m1Mb3qfgeHpHHA3wE/qXcsA5WkHYBD\ngJ8CRMTaiHi5vlFt4H3AExHx53oHQnbH61BJDcAw1k8NVS+TgT9GxKqIaAfuAI7d0kFspK88Grgs\nLV8GHFNNW1t1UhnoJE0A9gP+WN9IuoeZ7gOeA26JiLrHBHwf+Eegs96B5ATZ1EIL01RA9TaR7Ldd\nl6Rhwp9IGl7voCqcAPy83kFExDLgfLLfx60AXomIm+sbFQ8CB0saJWkYcAQ9f+BdT7tExIq0/Ayw\nSzWVnFTqRNJ2wC+BL0XEq/WOJyI60lDFOGBaUdPlbC5JRwLPRcTCesbRi/dExLvIZso+TdIhdY6n\nAXgXcFGa7fsNqhym2BLSj5SPAn4xAGIZSfbteyKwOzBc0qfqGVNEPAx8F7gZ+A1wH9BRz5h6k34/\nWNXohZNKHUhqJEsoV0TEr+odT14aOplP/a9FHQQcJekpstmoD5P0H/UNqfvbLhHxHNk1gmn1jYg2\noC13Znk1WZIZKA4H7omIZ+sdCNmEtX+KiJURsQ74FfA3dY6JiPhpROwfEYcALwGP1Tum5FlJuwGk\n9+eqqeSksoVJEtn498MR8b16xwMgaYykHdPyUOADwCP1jCkivhER4yJiAtnwyW8joq7fKiUNlzSi\naxn4INnwRd1ExDPAUklds8m+j2wmioHiRAbA0FfyNHCgpGHp3+H7GAA3NUjaOb3vQXY95cr6RtTt\neuDktHwycF01leo9S3FNSfo5cCgwWlIbcFZE/LS+UXEQ8GnggXQNA+B/RsQNdYxpN+Cy9BC0EtmD\n0wbELbwDzC7ANVl/RANwZUT8pr4hAfBF4Io01PQkcEqd4wG6E+8HgL+vdywAEfFHSVcD95DdhXkv\nA2N6lF9KGgWsI5uSaovfaNFbXwmcB8yT9Bngz8DHq2rL07SYmVlRPPxlZmaFcVIxM7PCOKmYmVlh\nnFTMzKwwTipmZlYYJxWzzSSpo2Im3sJ+yS5pwkCaXdusWlv171TMamx1mtrGzBKfqZgVLD1z5V/T\nc1f+u2sq83T28VtJiyTdln5BjaRdJF2Tnmdzv6SuqUPKki5Oz9m4Oc12gKTT0/N4Fkm6qk6HadYr\nJxWzzTe0Yvjr+Ny+VyJiH+CHZLMtA/wf4LKI2Be4Arggbb8AuCM9z+ZdwOK0fU/gwojYC3gZ+Gja\nPgvYL7Xz+VodnNnm8C/qzTaTpNcjYrtetj9F9tCzJ9Pkoc9ExChJzwO7RcS6tH1FRIyWtBIYFxFr\ncm1MIHsEwZ5p/etAY0ScK+k3wOvAtcC1uWfhmNWdz1TMaiM2stwfa3LLHay/Bvp3wIVkZzUL0gOn\nzAYEJxWz2jg+935XWv4D6x9f+0ngd2n5NuBU6H5Y2g4ba1RSCRgfEfOBrwM7ABucLZnVi7/hmG2+\nobmZpiF7TnzXbcUjJS0iO9s4MW37ItkTGr9G9rTGrtmEzwDmpNlgO8gSzAp6Vwb+IyUeARcMwMcH\n2zbM11TMCpauqbRExPP1jsVsS/Pwl5mZFcZnKmZmVhifqZiZWWGcVMzMrDBOKmZmVhgnFTMzK4yT\nipmZFeb/A7+OGnZt6TtaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq7fmArk0bIN",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.3 モデルによる予測\n",
        "\n",
        "1.2.2で学習させたモデルによって予測を行ってみましょう。Sequential.predict関数によって予測が行えます。\n",
        "\n",
        "主な引数は次の通りです。\n",
        "\n",
        "* x_test：予測に使用する入力データ\n",
        "* batch_size：まとめて1度に予測を行うサンプル数\n",
        "* verbose：評価のログを出力するか（0:しない(デフォルト)、1：する）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7CJSTL50bIN",
        "colab_type": "code",
        "outputId": "c85b283d-fbf9-4a5b-c1bd-c66218dd578b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classes = model.predict(x_test, batch_size=128, verbose=1)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 31us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sTY0plvOe-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1324
        },
        "outputId": "35c0c77d-ccf5-46f7-814b-6a616c912f0f"
      },
      "source": [
        "# データセットの推論結果と元画像を確認\n",
        "# test_numを0～9999で指定してください\n",
        "test_num=1001\n",
        "\n",
        "print(\"推論結果：\"+str(classes[test_num].argmax()))\n",
        "print(np.squeeze(x_test[test_num]))\n",
        "test_img = np.squeeze(x_test[test_num])\n",
        "test_img = 255 - test_img\n",
        "plt.imshow(test_img,'gray')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "推論結果：0\n",
            "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11.\n",
            "   82. 255. 176.  88.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 107.\n",
            "  252. 253. 252. 222. 113.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  48. 166. 241.\n",
            "  252. 253. 252. 252. 230.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 131. 252. 252.\n",
            "  252. 169.  73. 172. 230.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  20. 236. 252. 252.\n",
            "  156.   0.   0. 100. 235.  20.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 175. 252. 252. 192.\n",
            "    7.   0.   0.  65. 249. 193.  19.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  27. 224. 252. 226.  44.\n",
            "    0.   0.   0.   0. 238. 252.  55.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  75. 252. 250.  82.   0.\n",
            "    0.   0.   0.   0. 132. 252. 122.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   7. 192. 252. 208.   0.   0.\n",
            "    0.   0.   0.   0.  99. 252. 191.   7.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.  23. 252. 252.  84.   0.   0.\n",
            "    0.   0.   0.   0.  23. 252. 252.  21.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0. 133. 253. 242.  19.   0.   0.\n",
            "    0.   0.   0.   0.  23. 253. 253.  22.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0. 132. 252. 164.   0.   0.   0.\n",
            "    0.   0.   0.   0.  52. 252. 252.  21.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0. 132. 252. 164.   0.   0.   0.\n",
            "    0.   0.   0.   0. 132. 252. 218.  13.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0. 132. 252. 172.   2.   0.   0.\n",
            "    0.   0.   0.   0. 190. 252. 164.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.  61. 252. 252.  46.   0.   0.\n",
            "    0.   0.   0.  66. 249. 252. 164.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.  15. 222. 252. 226.  78.   0.\n",
            "    0.   0.   0. 137. 252. 252.  78.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  65. 252. 252. 239. 198.\n",
            "  122. 122. 198. 249. 242. 131.  29.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  46. 224. 252. 252. 252.\n",
            "  252. 253. 252. 252. 230.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  23. 169. 219. 252.\n",
            "  252. 253. 252. 252. 196.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   2.  38. 224.\n",
            "  252. 253. 175. 190.  20.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f528829aeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANB/T86llctN2druAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B2-3A2nVfuj",
        "colab_type": "text"
      },
      "source": [
        "自分で手書きした画像を推論させてみましょう。\n",
        "\n",
        "手書きファイルをアップロードし、ファイル名を指定して実行します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDEx3_iRNpGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "73d3fb9a-fe15-40d2-9b3a-3aa2cb046d19"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Google Colabにファイルをアップロード\n",
        "# アップロードしたファイルを指定\n",
        "img_path=\"./eight001.png\"\n",
        "img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
        "img = 255 - img\n",
        "cv2_imshow(img)\n",
        "\n",
        "img = cv2.resize(img, dsize=(28,28))\n",
        "img = img.reshape(1, 28, 28 ,1)\n",
        "img = img.astype(np.float32)\n",
        "pred = model.predict(img,verbose=1)\n",
        "\n",
        "# 推論処理\n",
        "print(\"推論結果：\"+str(pred.argmax()))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAZklEQVR4nNWSQRKAMAgDScf/fzke\nrEogcpcTk4VCmEYMgSdjFVJOU7/6Y2yQqYcVXgwQWp/N+wikDKyd3OxuN1ZebTXFZuYM5ghfViBO\nuk8MULawMz3kBINScESjthNRQxTzjX4UJ6z1EikU0pVXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F528824AC88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 2ms/sample\n",
            "推論結果：8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIXwHVGJ0bIP",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.4 モデルの可視化\n",
        "\n",
        "1.1.1で作成したモデルをTensorBoardをにて参照してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyx_anHq0bIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Web参照のため、ngrokを利用\n",
        "if not os.path.exists('./ngrok'):\n",
        "    !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "    !unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# TensorBoardおよびngrokの起動\n",
        "import subprocess\n",
        "cmd = \"tensorboard --logdir=./logs --host 0.0.0.0 --port 6006 &\"\n",
        "proc_tb = subprocess.call(cmd, shell=True)\n",
        "\n",
        "cmd = \"./ngrok http 6006 &\"\n",
        "proc_ng = subprocess.call(cmd, shell=True)\n",
        "\n",
        "# TensorBoard URL\n",
        "!curl -s http://localhost:4040/api/tunnels | python -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH37JEOU0bIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorBoardプロセスの停止\n",
        "#!ps -ef | grep tensorboard | grep -v grep | awk '{print \"kill -9\",$2}'| sh\n",
        "\n",
        "# ngrokプロセスの停止\n",
        "#!ps -ef | grep ngrok | grep -v grep | awk '{print \"kill -9\",$2}'| sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP3EQso80bIX",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 各モデルLayer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "mBI02lgi0bIY",
        "colab_type": "text"
      },
      "source": [
        "ここからは、layerクラスについて詳しくみていきましょう。\n",
        "\n",
        "MLPで中心的な存在である、層を表すクラスがlayerクラスです。\n",
        "\n",
        "layerには様々な種類があり、そのそれぞれが独自の機能を持っているので、役割をある程度覚えておきましょう。\n",
        "\n",
        "今回は最もオーソドックスなlayerとして、keras.layers.core以下に定義されている中で使用頻度の高いものを紹介します。\n",
        "\n",
        "https://keras.io/ja/layers/about-keras-layers/\n",
        "\n",
        "https://keras.io/ja/layers/core/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN8uh6OD0bIZ",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1 Dense\n",
        "\n",
        "一般的な全結合層を表すレイヤーです。つまり、入力$u\\in\\mathbb{R}^D$に対して、\n",
        "\n",
        "$v = \\sigma(Wu+b) \\in\\mathbb{R}^{D'}$\n",
        "\n",
        "を出力します。\n",
        "\n",
        "なお、$W\\in\\mathbb{R}^{D' \\times D}$は重み行列を表し、$b\\in\\mathbb{R}^{D'}$はバイアスを表しています。\n",
        "\n",
        "重み行列とバイアスは学習によって値が決まることに注意しましょう。\n",
        "\n",
        "また$\\sigma(x):\\mathbb{R}^{D'}\\to\\mathbb{R}^{D'}$は**活性化関数**と呼ばれるもので、任意に指定可能です。\n",
        "\n",
        "（実際には最後の出力層の活性化関数については問題の特性から決まることも多いです）\n",
        "\n",
        "一般に活性化関数には非線形関数を指定することで、MLPの性能を向上させます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBqWuwzq0bIZ",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "keras.layers.core.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
        "                        kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
        "                        kernel_constraint=None, bias_constraint=None)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY0pofdt0bIa",
        "colab_type": "text"
      },
      "source": [
        "主な引数は\n",
        "\n",
        "* units: 出力ユニット数($N$)\n",
        "* activation: 出力ユニットに適用する活性化関数、Activationレイヤーの説明を参照\n",
        "* use_bias: バイアス$b$を使用するか\n",
        "* kernel_initializer: 重み行列$W$の初期化方法（initializerについては3章で扱います）\n",
        "* bias_initializer: バイアス$b$の初期化方法（initializerについては3章で扱います）\n",
        "\n",
        "です。またshapeの入出力での変化は\n",
        "\n",
        "<ol>(batch_size, ..., input_dim) --> (batch_size, ..., units)</ol>\n",
        "\n",
        "のとおり、一番深いネストの次元がinput_dimからunitsに変わるだけです。\n",
        "\n",
        "1.1.1のモデルの構築で出てきた例を以下に再掲します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJvncM_u0bIa",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "model.add(Dense(units=256, input_shape=(784,))) # 次元の変化: 784 -> 256\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(units=100)) # 次元の変化: 256 -> 100\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(units=10)) # 次元の変化: 100 -> 10\n",
        "model.add(Activation('softmax'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2auB_GX0bIb",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2 Activation\n",
        "\n",
        "入力に対して活性化関数を適用したものを出力します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqGENA-u0bIc",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "keras.layers.core.Activation(activation)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt8mkQnU0bId",
        "colab_type": "text"
      },
      "source": [
        "引数は\n",
        "\n",
        "* activation: 適用する活性化関数\n",
        "\n",
        "のみです。（入力と出力でshapeは変わりません）\n",
        "\n",
        "活性化関数として使用できる関数の一覧はこちら( https://keras.io/ja/activations/ )です。\n",
        "\n",
        "よく使用されるものを以下に示します。\n",
        "\n",
        "* sigmoid: $f(x)=\\dfrac{1}{1+e^{-x}}$\n",
        "* ReLU: $f(x)=\\max(0,x)$\n",
        "* tanh: $f(x)=\\tanh(x)=\\dfrac{e^x-e^{-x}}{e^x+e^{-x}}$\n",
        "* softmax: $f(x)=\\dfrac{\\exp(x_d)}{\\sum_{d'} \\exp(x_{d'})} \\quad (x\\in\\mathbb{R}^D,\\ d=1,2,\\ldots,D)$\n",
        "\n",
        "特にsoftmax関数は出力が規格化されているので、確率として解釈できるため多クラス分類タスクの出力層に使用されることが多いです。\n",
        "\n",
        "（2クラス分類であればsigmoid関数を出力層に使用することも多いです）\n",
        "\n",
        "ここで、活性化関数をプロットしてみましょう。(多変数関数のsoftmaxを除く)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-tULG5p0bId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1+np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "fig = plt.figure()\n",
        "x = np.linspace(-10, 10, 1000)\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(x, sigmoid(x), label='sigmoid')\n",
        "ax.plot(x, relu(x), label='ReLU')\n",
        "ax.plot(x, tanh(x), label='tanh')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlim(-5, 5)\n",
        "plt.ylim(-1.1, 2)\n",
        "plt.grid(which='major',color='gray',linestyle='-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deHEnYOR0bIh",
        "colab_type": "text"
      },
      "source": [
        "1.1.1のモデルの構築で出てきた例を以下に再掲します。\n",
        "\n",
        "```py\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "model.add(Dense(units=256, input_shape=(784,)))\n",
        "model.add(Activation('relu')) # 活性化関数として relu を選択\n",
        "model.add(Dense(units=100))\n",
        "model.add(Activation('relu')) # 活性化関数として relu を選択\n",
        "model.add(Dense(units=10))\n",
        "model.add(Activation('softmax')) # 活性化関数として softmax を選択\n",
        "```\n",
        "\n",
        "なお、活性化関数はDenseレイヤーなどで直接指定することも可能で、実際に以下のコードは上記と同じ結果になります。\n",
        "\n",
        "```py\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "model.add(Dense(256, input_shape=(784,), activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYfUF8xS0bIh",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.3 Flatten\n",
        "\n",
        "入力をフラット化します。つまり、リストの入れ子になっているデータを1つのリストに展開します。\n",
        "\n",
        "(Ex. [[1,2,3],[4,5,6],[7],[8,9]]->[1,2,3,4,5,6,7,8,9])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_aoflDN0bIi",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "keras.layers.core.Flatten()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSZWJUX40bIj",
        "colab_type": "text"
      },
      "source": [
        "例は次の通りです。（出力shapeはbatch_sizeを除く入力shapeの積）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9jK50yV0bIj",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), input_shape=(3, 32, 32))) # 次元の変化: (3, 32, 32) -> (64, 32, 32)\n",
        "# Conv2Dは未修ですが、ここではその機能は関係ないので気にしなくて結構です\n",
        "\n",
        "model.add(Flatten()) # 次元の変化: (64, 32, 32) -> (65536,) (65536 = 64*32*32)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYY9lzSH0bIk",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.4 Reshape\n",
        "\n",
        "入力を指定のshapeに変換して出力します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPX796mW0bIl",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "keras.layers.core.Reshape(target_shape)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei7rOqVE0bIl",
        "colab_type": "text"
      },
      "source": [
        "引数は\n",
        "* target_shape: 変換先のshapeを表す整数のタプル、ただしサンプルの次元（バッチサイズ）を含まない\n",
        "\n",
        "例は次の通りです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRui-nh80bIm",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "model = Sequential()\n",
        "model.add(Reshape((3, 4), input_shape=(12,))) # 次元の変化: (12,) -> (3, 4)\n",
        "\n",
        "model.add(Reshape((6, 2))) # 次元の変化: (3, 4) -> (6, 2)\n",
        "\n",
        "# `-1`をしていすると、その次元については推定してくれます(6/2=3)\n",
        "model.add(Reshape((-1, 2, 2))) # 次元の変化: (6, 2) -> (?, 2, 2)=(3, 2, 2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucQ7uJRM0bIm",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.5 Permute\n",
        "\n",
        "入力の次元を入れ替えます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VngIwkch0bIn",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "keras.layers.core.Permute(dims)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvjF9_0E0bIo",
        "colab_type": "text"
      },
      "source": [
        "引数は\n",
        "\n",
        "* dims: 次元の入れ替え方を指定する整数のタプル、サンプルの次元はふくまない1から始まるindexで指定\n",
        "\n",
        "です。（入力と出力でshapeは変わりません）\n",
        "\n",
        "例は次の通りです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDR5EyED0bIp",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "model = Sequential()\n",
        "model.add(Permute((2, 1), input_shape=(10, 64))) # 次元の変化: (10, 64) -> (64, 10)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W67nYpg0bIr",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.6 RepeatVector\n",
        "\n",
        "入力を指定回数繰り返します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtMC1sJV0bIr",
        "colab_type": "text"
      },
      "source": [
        "```py\n",
        "keras.layers.core.RepeatVector(n)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd8GrtJI0bIs",
        "colab_type": "text"
      },
      "source": [
        "引数は\n",
        "\n",
        "* n: 入力の複製回数\n",
        "\n",
        "です。またshapeの入出力での変化は\n",
        "\n",
        "<ol>(num_samples, features) --> (num_samples, n, features)</ol>\n",
        "\n",
        "であり、入力には2階のテンソルのみを受け付けます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F18fL6Cx0bIt",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 損失関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ36NEcz0bIv",
        "colab_type": "text"
      },
      "source": [
        "モデルの学習にあたっては、損失関数の最小化を行うわけでした。そこで、続いて損失関数についてみていきます。\n",
        "\n",
        "https://keras.io/ja/losses/\n",
        "\n",
        "kerasではモデルをコンパイルする際に損失関数を設定します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JbXxomQ0bIw",
        "colab_type": "text"
      },
      "source": [
        "損失関数の選択においては、出力値が連続な場合と離散な場合で大きく異なってきます。\n",
        "\n",
        "#### 連続値のとき\n",
        "\n",
        " 主に使用されるのは**平均二乗誤差**です。これは各ミニバッチのデータ数を$N$として、\n",
        "\n",
        " $$E=\\dfrac{1}{N}\\sum_{n=1}^{N}(y_n-t_n)^2$$\n",
        "\n",
        " として表されます。(なお、$y_n, t_n$はそれぞれ入力$x_n$に対するモデルの出力値(y_pred)と出力データ(y_true)を表す)\n",
        "\n",
        " この平均二乗誤差を使用する場合、compile関数の引数として`loss='mean_squared_error'`を指定します。\n",
        "\n",
        "\n",
        "#### 離散値のとき\n",
        "\n",
        "主に使用されるのは、**（多クラス）交差エントロピー**です。2クラス分類の場合は交差エントロピーとして\n",
        "\n",
        "$$E=-\\dfrac{1}{N}\\sum_{n=1}^N \\left[t_n \\ln y_n + (1-t_n) \\ln (1-y_n) \\right]$$\n",
        "\n",
        "を使用し、多クラス分類（Kクラス）の場合は多クラス交差エントロピーとして\n",
        "\n",
        "$$E=-\\dfrac{1}{N}\\sum_{n=1}^N \\sum_{k=1}^K t_{nk} \\ln y_{nk}$$\n",
        "\n",
        "を用います。それぞれcompile関数の引数として`loss='binary_crossentropy'`、`loss='categorical_crossentropy'`を指定することで使用できます。\n",
        "    \n",
        "\n",
        "今回利用したMNISTは0~9の離散値であるため、以下のように多クラス交差エントロピーを利用しています。\n",
        "\n",
        "```py\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBYBfyw90bIx",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 評価関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEWYC4ua0bIy",
        "colab_type": "text"
      },
      "source": [
        "評価関数(metric)はモデルの出力の良し悪しを評価します。\n",
        "\n",
        "損失関数もモデルの良し悪しの指標となるという点では同じですが、損失関数は最適化計算をとおして学習に直接的に影響するのに対して、評価関数は学習には使用されず、あくまでその時点でのモデルの評価指標を出力するのみであるという違いがあります。\n",
        "\n",
        "つまり、compile関数で指定すると、訓練やテストの際に参考情報として評価関数の値が返り値として受け取れるというだけです。\n",
        "\n",
        "評価関数として使用することが多いのは**accuracy(正解率)**です。（正解率＝全体のデータに対して予測値が答えと一致した割合）\n",
        "\n",
        "これはcompile関数の引数として、`metrics=['acc']`を指定することで使用できます。（リストに他の損失関数を含めれば、それらも同時に評価されます）\n",
        "\n",
        "https://keras.io/ja/metrics/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kDw9ZBi0bIz",
        "colab_type": "text"
      },
      "source": [
        "### 1.5 Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKNk1bRK0bIz",
        "colab_type": "text"
      },
      "source": [
        "ここまではkeras.models.Sequentialクラスを用いたモデル構築を説明しました。\n",
        "\n",
        "Sequentialクラスを用いる場合はadd関数を使用して簡単にモデルを構築できますが、途中に分岐や合流があるような複雑なモデルは作成できません。\n",
        "\n",
        "こうしたより複雑なモデルの構築には別の方法が用意されています。それが**Functional API**です。この特徴は\n",
        "\n",
        "* **Inputレイヤー**から構築を始める\n",
        "* 各レイヤーの返り値（テンソル）を次のレイヤーの入力として順々に構築していく\n",
        "* **keras.models.Modelクラス**に入力と出力を指定することでインスタンス化\n",
        "\n",
        "という点です。一度Modelクラスのインスタンスを作ってしまえば、後の学習等はSequentialクラスによる場合と同様です。\n",
        "\n",
        "より詳しくは、実際にFunctional APIが必須になる第4回で扱いますが、すぐにFunctional APIの発展的な利用法をみたいという方は、\n",
        "\n",
        "下記の公式HPのリンクにいくつか記載がありますので参考にしてみてください。\n",
        "\n",
        "https://keras.io/ja/getting-started/functional-api-guide/\n",
        "\n",
        "https://keras.io/ja/models/model/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKmaNCMW0bI2",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 確認問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjyPeDPG0bI3",
        "colab_type": "text"
      },
      "source": [
        "1. 学習データ以外の未知のデータに対するモデルの予測性能を何というか  \n",
        "  ①神通力　②バイアス　③汎化性能　④共起性\n",
        "2. データセット全体を一度に全て使用して学習する方法を何というか  \n",
        "  ①転移学習　②ワンショット学習　③過学習　④バッチ学習　\n",
        "3. 名義尺度のデータをバイナリベクトルによって表現したものを何というか  \n",
        "  ①分散表現　②one-hot表現　③ビット表現　④ユニタリ表現\n",
        "4. モデルの学習に当たって最小化するものは何か  \n",
        "  ①精度　②損失関数　③スコア　④F値"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RKTQVB80bI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}